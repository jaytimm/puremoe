"doc_id","paragraph_id","chunk_id","chunk","text_id"
"file.pdf","1ED",1,"a11111","file.pdf~1ED~1"
"file.pdf","OPENACCESS",2,"OPENACCESS
Citation: Croijmans I, Majid A (2016) Not All Flavor Expertise Is Equal: The Language of Wine and Coffee Experts. PLoS ONE 11(6): e0155845. doi:10.1371/journal.pone.0155845
Editor: Sidney Arthur Simon, Duke University Medical Center, UNITED STATES
Received:
January 19, 2016
Accepted:
May 5, 2016
Published:
June 20, 2016
Copyright: © 2016 Croijmans, Majid. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
Data Availability Statement: All datafiles are available without restricitons from The Netherlands Organisation for Scientific Research (NWO) Data Archiving and Networking Service (DANS) Repository. The DOI for the dataset is http://dx.doi. org/10.17026/dans-zke-2wgq, and the full citation for the dataset is: Majid, Prof. Dr. A (Radboud University); Croijmans, MSc. I (Radboud University) (2016): Human olfaction at the intersection of language, culture and biology. DANS. http://dx.doi. org/10.17026/dans-zke-2wgq
Funding: Funding was provided by Netherlands Organisation for Scientific Research, grant number 277-70-011, http://www.nwo.nl/en/research-and-
RESEARCHARTICLE","file.pdf~OPENACCESS~2"
"file.pdf","Not All Flavor Expertise Is Equal: The Language of Wine and Coffee Experts",3,"Not All Flavor Expertise Is Equal: The Language of Wine and Coffee Experts
Ilja Croijmans 1,2 * , Asifa Majid 1,3,4
1 Centre for Language Studies, Radboud University, Nijmegen, The Netherlands, 2 International Max Planck Research School for Language Sciences, Nijmegen, The Netherlands, 3 Donders Institute for Brain, Cognition, and Behaviour, Radboud University, Nijmegen, The Netherlands, 4 Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands
* i.croijmans@let.ru.nl","file.pdf~Not All Flavor Expertise Is Equal: The Language of Wine and Coffee Experts~3"
"file.pdf","Abstract",4,"Abstract
People in Western cultures are poor at naming smells and flavors. However, for wine and coffee experts, describing smells and flavors is part of their daily routine. So are experts better than lay people at conveying smells and flavors in language? If smells and flavors are more easily linguistically expressed by experts, or more ' codable ' , then experts should be better than novices at describing smells and flavors. If experts are indeed better, we can also ask how general this advantage is: do experts show higher codability only for smells and flavors they are expert in (i.e., wine experts for wine and coffee experts for coffee) or is their linguistic dexterity more general? To address these questions, wine experts, coffee experts, and novices were asked to describe the smell and flavor of wines, coffees, everyday odors, and basic tastes. The resulting descriptions were compared on a number of measures. We found expertise endows a modest advantage in smell and flavor naming. Wine experts showed more consistency in how they described wine smells and flavors than coffee experts, and novices; but coffee experts were not more consistent for coffee descriptions. Neither expert group was any more accurate at identifying everyday smells or tastes. Interestingly, both wine and coffee experts tended to use more source-based terms (e.g., vanilla ) in descriptions of their own area of expertise whereas novices tended to use more evaluative terms (e.g., nice ). However, the overall linguistic strategies for both groups were en par. To conclude, experts only have a limited, domain-specific advantage when communicating about smells and flavors. The ability to communicate about smells and flavors is a matter not only of perceptual training, but specific linguistic training too.","file.pdf~Abstract~4"
"file.pdf","Introduction",5,"Introduction
Wine, coffee, cheese, and chocolate would all taste bland without the sense of smell. Even though smells are omnipresent in our daily lives, people struggle with odor and flavor naming (i.e., the multisensory experience in the mouth including gustatory, olfactory, and somatosensory sensations; [1,2]). If asked to name everyday odors, like peanut butter, cinnamon or strawberry, most people can only name half of them correctly [3 -6].
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
1/21
results/research-projects/i/81/8281.html. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.
Competing Interests: The authors have declared that no competing interests exist.
Experts ' Flavor Naming
At the same time, there is a lucrative industry around language and flavor. Influential wine experts have considerable impact on the price and sales of a wine just through their reviews [7]. This is an interesting state of affairs, as some wine authors themselves acknowledge the limits of language when describing smells and flavors [8 -10].
English, like other Western languages, appears to have a restricted vocabulary for smells and tastes [11,12]. A simple comparison of the brute number of terms for the senses leaves smell and taste at the bottom of the hierarchy [13,14]. When English speakers do try to name smells and flavors they overwhelmingly rely on source-descriptions (e.g., it smells like a banana; it tastes like chicken) or metaphors (e.g., it smells green; it tastes wicked) . Furthermore, English speakers show low accuracy, consistency and agreement in how they describe smells and flavors (e.g. [15 -19]).","file.pdf~Introduction~5"
"file.pdf","Introduction",6,"Introduction
Recently the universality of these findings has been questioned [20,21]. For example, Jahai [21,22] and Maniq [23], two Aslian languages spoken in the Malay Peninsula by hunting-gathering communities, have dedicated vocabulary for smells. The smell of different perfumes, flowers, durian and bearcat ( Arctitis binturong) is described by the Jahai as ltp ɨ t , whereas Maniq might describe the smell of some food (e.g., tubers), bearcat, clean clothes, and some trees with lsp ə s [22,23]. Majid and Burenhult [21] also found Jahai speakers name odors as easily as colors, unlike English speakers who struggled to name the same odors. This raises the possibility that the difficulty people have in naming smells and flavors could be a WEIRD (Western, Educated, Industrialized, Rich, Democratic [24]) affair.
Odors play an important role in Jahai daily life. This is reflected not only in language, but in various aspects of Jahai culture, such as religion and medicine [22]. According to the Jahai, some types of illness are cured by healing magic involving fragrant smells from plants and burnt resins, for example. Similarly, personal names are often drawn from the names of fragrant plants and flowers. For the Jahai, a cultural preoccupation with odors, therefore, aligns with their dexterity in talking about smells.
In the West, naming odors and flavors is also important for some people. Like perfumers, wine experts have years of training and experience in appreciating and describing odors, as well as flavors [25]. This is illustrated by ' tastings ' , during which experts describe and discuss wines, and compare notes. So wine experts can be considered to be part of a distinct sub-culture with its own communicative practices and rituals around smells and flavors (cf. [26]). Considering the significance of flavor in their occupation, then, are wine experts, or other flavor experts, better at describing smells and flavors than novices? And, if so, what linguistic strategies do they use? The previous literature shows no general agreement on these matters, as described below.","file.pdf~Introduction~6"
"file.pdf","The language of wine experts",7,"The language of wine experts
Wine is a complex entity, with as many as 800 different aromatic volatiles that together create a high dimensional flavor experience [27]. How do wine experts and novices convey their personal wine experience to each other given this complexity?
Cain [3] has suggested wine experts appreciate flavors in a different way than novices. A casual perusal of wine reviews certainly adds to this impression. Consider this tasting note:
The 2001 Batard-Montrachet offers a thick , dense aromatic profile of toasted white and yellow fruits . This rich , corpulent offering reveals lush layers of chewy buttered popcorn flavors . Medium-bodied and extroverted , this is a street-walker of a wine , making up for its lack of class and refinement with its well-rounded , sexually-charged assets . Projected maturity : now2009 . ([28] p. 57)
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
2/21
Experts ' Flavor Naming
As Suarez-Toste [28] notes, this description contains many figurative and metaphorical constructions. Metaphors are ubiquitous in experts ' wine descriptions [28 -31]: wines are described as having a body (e.g., ' this rich, corpulent offering ' [28]) and persona (e.g. ' making up for its lack of class and refinement ' [28]). Wines are also described as if they were animate, and capable of motion (e.g., ' This wine bursts from the glass with violets ' [32]).
So, it seems as if wine experts are vague and literary in their descriptions. However, other studies suggest experts use more concrete words (e.g., blackberries instead of fruity ; [33 -36]), and provide more precise labels (e.g., gooseberry instead of fruit [37]). It has also been suggested experts use more wine-domain specific terminology (e.g., metallic , mineral , unripe [38,39]), more technical terms (e.g., aldehyde ), and make less reference to hedonic value (e.g., unpleasant [40]). Thus, there is contradictory evidence about the types of strategies experts use to convey their experiences.","file.pdf~The language of wine experts~7"
"file.pdf","The language of wine experts",8,"The language of wine experts
Turning to whether experts have more communicative success than novices, the jury is also out. On the one hand, there are studies suggesting wine experts might have an advantage over novices in how they communicate about wines. Wine experts appear to agree with each other more about how to name wine-related odors than novices or intermediate wine students [37,41 -43]. Some studies have also found expert descriptions are more often matched to the correct wine than descriptions composed by novices [34,35,44]. This fits with the idea proposed by Smith [45] that experts agree more on the smell and flavor of wine, given their shared experiences.
On the other hand, other studies suggest experts are not better at describing flavors than novices. For example, Lawless [34] compared expert wine descriptions to those of novices, and found expert descriptions were highly idiosyncratic, with most terms used only once by one participant. This suggests there is little systematicity between experts. In another study, experts showed similar levels of agreement as novices in their descriptions of wine-related odors [46]. However these studies can be interpreted in a different way. Lawless [34] did not directly compare the two groups on consistency, so we cannot be sure whether experts and novices were similar or different on this measure. Similarly, a closer look at the data in Parr et al. [46] shows experts had numerically higher identification and consistency rates than novices, leaving open the possibility the study was underpowered (as suggested by the authors also, on p. 752). Overall, the few studies conducted to date contradict each other, and leave open the question of whether experts are better at naming odors and flavors.","file.pdf~The language of wine experts~8"
"file.pdf","Howgeneral is expertise?",9,"Howgeneral is expertise?
If wine experts are indeed better at naming odors and flavors, this leads to the question of how well odor naming in one domain generalizes to another. That is, if there is an odor naming advantage for wine experts, does it hold for odors outside of their domain of expertise? Zucco and colleagues [37] found wine experts were better at naming odors than intermediate wine students, but this advantage was restricted to wine-related odors only, and did not extend to household odors. A more recent study [40] compared the language different experts (flavorists and perfumers) used to describe common odors. Flavorists and perfumers used different words than novices, but they found no difference between expert groups, which could indicate flavor experts possess a general ability to express smells and flavors in language.
Sezille et al. [40] are unusual in comparing flavorists and perfumers. Most previous studies focus exclusively on wine experts, and compare them to novices (for a recent review, see [47]). In fact, there are many expert domains which would make for an interesting comparison to wine. Take coffee, for example. Just like wine, coffee contains more than 800 volatile aroma components (cf. [48,49]). There is an extensive literature regarding the growth, harvest,
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
3/21
Experts ' Flavor Naming
processing, production, and marketing of both wines and coffees. In addition, experts in both domains typically undergo extensive training: it takes many years of experience to become an expert in either specialty.","file.pdf~Howgeneral is expertise?~9"
"file.pdf","Howgeneral is expertise?",10,"Howgeneral is expertise?
Nevertheless, coffee and wine expertise also differs in some interesting respects. Whereas wines are usually elaborately described in tasting notes, menus, and on placards in stores, the descriptions of coffees tend to be less frequently encountered. This can be quantified further in a number of ways. For example, there are at least 10 different subscription magazines to be found about wine on Amazon.com, but not a single one for coffee (retrieved December 1 st 2015). A simple Google search on both topics reveals a similar asymmetry: a Dutch query for wine tasting notes ( ' wijn ' AND ' proefnotitie ' ) returned 77,000 web pages containing wine tasting notes, while a similar query for coffee ( ' koffie ' AND ' proefnotitie ' ) returned a mere 10,000 web pages containing coffee tasting notes (retrieved October 16 th 2015). The same query in English revealed a similar picture: 501,000 results for wine tasting notes ( ' wine ' AND ' tasting note ' ) versus only 81,000 for coffee tasting notes ( ' coffee ' AND ' tasting note ' , retrieved December 8 th 2015). Likewise, any reasonably priced restaurant will provide a written description of wines on the menu; most supermarkets provide additional information about the wines they sell. But comparably detailed descriptions of coffees are rare. This asymmetry could be attributed to the number of wine vs. coffee experts, but this still could have relevance for sensory language. Studies demonstrate more exposure to more varied input from different people can influence language use (e.g. [50]). For this reason, in this study we compared coffee experts to wine experts on the same flavor and odor naming tasks. If domain-specific linguistic experience matters, then wine and coffee experts should behave differently because there are more (in number) and more varied (number of people producing) descriptions for wines than coffees.
The question we asked is whether smells and flavors are linguistically expressed more easily by wine and coffee experts than by novices. Are they more ' codable ' ? Items that are more codable in language have (1) shorter lengths; (2) dedicated vocabulary for their expression; and (3a) are named more consistently and (3b) correctly (cf. [21,51]). We tested whether experts and novices differ on these measures in how they describe smells and flavors.","file.pdf~Howgeneral is expertise?~10"
"file.pdf","Howgeneral is expertise?",11,"Howgeneral is expertise?
If the chemical senses are easier to communicate about for experts who have perceptual expertise and training in smells and flavors, like the wine and coffee experts in this study, then smells and flavors should be more linguistically codable for them than they are for novices. And this should be true regardless of the specific smells and flavors. That is, if wine or coffee expertise is equivalent to the kind of ' expertise ' the hunting-gathering Jahai have, then experts should be better at describing smells (and flavors) regardless of the source. If, on the other hand, expertise is limited, i.e., experts only have domain-specific expertise, then wine experts should show higher codability for wines; coffee experts for coffee; and neither group should differ from each other, or the novices, on basic odors and tastes. Finally, if the kind of language games around expertise is important (e.g., how often people write and talk about their domain of expertise), we might expect wine experts to show higher codability than coffee experts, because they engage in discussions over their specialty more often and receive more varied input.","file.pdf~Howgeneral is expertise?~11"
"file.pdf","Ethics statement",12,"Ethics statement
Each participant was informed about the purpose and methods of the study, and written consent was obtained before the experiment began. The study was approved by the institutional Ethics Assessment Committee of Radboud University.
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
4/21
Experts ' Flavor Naming","file.pdf~Ethics statement~12"
"file.pdf","Participants",13,"Participants
Sixty-three participants (22 women, M age = 43.7 years, SD = 11.7, age range: 24 -70 years) including wine experts, coffee experts, and novices participated in the experiment (see Table 1). Participants were actively recruited by approaching experts in stores, word-of-mouth, via websites and e-mail, and social media. Participants were not paid, but were reimbursed for travel as appropriate.
All participants were native speakers of Dutch, except for one wine expert, who moved from France to the Netherlands at a young age and spoke Dutch at near-native level. They were otherwise relatively homogenous. Wine experts had a vinologist degree and/or worked as a qualified, experienced vinologist or sommelier (cf. [39,46]). Coffee experts worked as qualified baristas, coffee roasters, or coffee brokers. The only criterion for novices was consumption of at least one glass of wine and one cup of coffee per week, to ensure they were familiar with the smell and flavor of both. In fact, the groups differed in wine and coffee consumption. Wine experts consumed significantly more wine than coffee experts or novices, χ 2 (6, N = 65) = 24.0, p = .001, Cramer ' s V = .43, while coffee experts consumed more coffee than wine experts or novices, χ 2 (6, N = 65) = 12.3, p = 0.056, Cramer ' s V = .31.
To validate the expertise levels of the wine and coffee experts, each participant completed three questionnaires: the Wine Knowledge Test [38,39,52], Coffee Knowledge Test (constructed in analogy to the Wine Knowledge Test), and a shortened version of the Odor Awareness Scale [53].","file.pdf~Participants~13"
"file.pdf","Participants",14,"Participants
There was a significant difference between groups on the Wine Knowledge Test F (2, 60) = 75.24, p < .001, η 2 = .71. Pairwise comparisons showed wine experts had significantly higher scores ( M = 6.6, SD = 1.0) than coffee experts ( M = 2.5, SD = 1.2), p < .001, d = 3.71 (Bonferroni correction is applied to pairwise comparisons throughout as appropriate), and novices ( M = 3.0, SD = 1.4), p < .001, d = 2.96; while coffee experts and novices did not differ from each other p = .551. Similarly, the groups differed on the Coffee Knowledge Test F (2, 59) = 36.34, p < .001, η 2 = .59. Coffee experts had significantly more coffee knowledge ( M = 6.1, SD = 1.7) than wine experts ( M = 2.7, SD = 1.2), p < .001, d = 2.31, and novices ( M = 2.8, SD = 1.5), p < .001, d = 2.06; whereas scores of novices and wine experts did not differ, p = .694. Finally, the scores of the Odor Awareness Scale also differed across groups F (2, 59) = 9.07, p= .001, η 2 = .24: Novices had significantly lower scores ( M = 23.9, SD = 9.2) than wine experts ( M = 31.6, SD = 8.3), p = .001, d = .88, and coffee experts ( M = 30.3, SD = 5.7), p= .030, d = .84, but both expert groups were equally aware of their sense of smell in daily life, p = .460. This further confirms olfaction is more important for both expert groups than the ordinary person.","file.pdf~Participants~14"
"file.pdf","Materials",15,"Materials
Wines. The five red wines originated from different countries, had different vinification styles, and were chosen for their distinct flavor profiles (in consultation with a vinologist who did not participate in the study; see Table 2). The bottles were opened at least 20 minutes before each testing session, checked for faults (e.g., corkstain), kept at room temperature (20 ± 2°C) in
Table 1. Participant characteristics.","file.pdf~Materials~15"
"file.pdf","Materials",16,"Materials
Table 1. Participant characteristics.
Number, Wine experts = 22. Number, Coffee experts = 20. Number, Novices = 21. Gender (number of women), Wine experts = 7. Gender (number of women), Coffee experts = 8. Gender (number of women), Novices = 7. Mean age, Wine experts = 45.8. Mean age, Coffee experts = 38.9. Mean age, Novices = 45.9. Age Range, Wine experts = 29 - 61. Age Range, Coffee experts = 26 - 52. Age Range, Novices = 24 - 70","file.pdf~Materials~16"
"file.pdf","Materials",17,"Materials
doi:10.1371/journal.pone.0155845.t001
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
5/21
Experts ' Flavor Naming
Table 2. Wines and coffees used in the study.","file.pdf~Materials~17"
"file.pdf","Materials",18,"Materials
Table 2. Wines and coffees used in the study.
1, Name = Jean Bousquet Malbec. 1, Country of production = Argentina. 1, Coffee = 1. 1, Name = Santa Helena Caturra. 1, Country of production = Colombia. 2, Name = Zenato Valpolicella Superiore. 2, Country of production = Italy. 2, Coffee = 2. 2, Name = Kirimiro Red Bourbon. 2, Country of production = Burundi. 3, Name = Altos R Rioja Temperanillo. 3, Country of production = Spain. 3, Coffee = 3. 3, Name = Knots Family Heirloom varietals. 3, Country of production = Ethiopia. 4, Name = Vallon des Sources Vacqueyras. 4, Country of production = France. 4, Coffee = 4. 4, Name = Fazenda Rainha Yellow Bourbon. 4, Country of production = Brazil. 5, Name = Castello de Molina Cabernet Sauvignon. 5, Country of production = Chile. 5, Coffee = 5. 5, Name = Hacienda Sonora Villa Sarch ï. 5, Country of production = Costa Rica","file.pdf~Materials~18"
"file.pdf","Materials",19,"Materials
doi:10.1371/journal.pone.0155845.t002
between sessions, and were kept refrigerated overnight. New bottles were opened every three days. Approximately 50 ml of each wine was poured in numbered, transparent crystal wine glasses with a volume of 400 ml.
Coffees. Five types of coffee beans from different countries with single estate origin were chosen for their distinct flavor profiles, in analogy with the selected wines (Table 2). These were selected in consultation with a Specialty Coffee Association Europe (SCAE) certified coffee roaster who did not participate in the study. The coffees were roasted in the same way in one batch. Immediately after roasting, the beans were sealed in dark aluminum coated plastic bags, in small lots of 100 grams. To ensure freshness of the coffee, at most three hours prior to testing 13.5 grams of each coffee was weighed and ground medium-fine. New sealed bags of coffee were opened every three days. The experimenter was trained by an independent SCAE barista to prepare the coffee following the Specialty Coffee Association America (SCAA) guidelines for cupping [54]. The coffees were presented in double-walled transparent cups of 250 ml and covered with numbered porcelain saucers until preparation.
Comparability of wine and coffee stimuli. As stated, wines and coffees were chosen to be equally distinct from one another. To verify whether the relative perceptual differences between wines and coffees were comparable, a separate experiment was conducted. Twenty naïve participants (13 women, M age = 24 years, SD = 4.8, age range = 18 -38) were asked to sort the five wines and five coffees based on how similar they were to one another. Half the participants sorted wines first; half coffee first. Participants indicated similarity by placing the glasses containing the drink on an A2 (42x49 cm) sheet of paper. The closer 2 stimuli were placed next to each other, the more similar the participant deemed them to be. The xand ycoordinates of each stimulus were recorded in millimeters and transformed into interstimulus distances for each stimulus pair.","file.pdf~Materials~19"
"file.pdf","Materials",20,"Materials
The mean distance for wines ( M = 254, SD = 53) was not significantly different to the mean distance between coffees ( M = 237, SD = 55) across participants t (19) = 1.88, p = .074, indicating wines and coffees were comparably perceptually different to each other. There was also a significant correlation between the relative distances between wines and coffees, r (18) = .703, p < .001, so if a participant sorted wines with a small interstimulus distance, they sorted the coffees in a similar way.
To further explore the perceptual space the wines and coffees occupied, two separate Multiple Factor Analyses were performed using the R package FactoMineR [55,56]. For both stimulus types, the data was best fitted with a maximal, four-dimensional solution, with eigenvalues for the four dimensions explaining respectively 42.8%, 23.3%, 18.3%, and 15.6% of the variance for the wines, and 38.8%, 25.6%, 19.6%, and 15.9% of the variance for coffee. This also points to the relative perceptual comparability of the two stimulus sets.
Odor stimuli. Participants had to name ten different odors. The odors were presented using Sniffin ' Sticks [57], and were a mixture of edible and inedible objects, covering the pleasantness continuum. The odors were lemon, apple, garlic, rose, chocolate, clove, mushroom, grass, leather, and cinnamon.
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
6/21
Experts ' Flavor Naming
Taste stimuli. Atotal of eight taste solutions, sweet, salty, bitter and sour, in strong and weak concentrations, were prepared. Refined sugar (10 grams, 292mM, sucrose ), salt (7.5 grams, 1283mM, sodium chloride ), quinine (0.05 grams, 1.54mM, quinine hydrochloride ) and citric acid (5 grams, 237mM) were dissolved in 100 ml of filtered, boiled water to make strong solutions. Weak solutions were half the concentration [17,18,58,59].","file.pdf~Materials~20"
"file.pdf","Procedure",21,"Procedure
Participants started naming either the wines or coffees first (order counterbalanced). For wines, participants were instructed to first smell and taste each wine, without talking, to familiarize themselves with the stimuli. The participant was then asked: ' Could you smell the first wine and describe the smell as precisely as possible? ' (in Dutch: Wilt u nu de eerste wijn ruiken en de geur zo precies mogelijk beschrijven? ). After describing the smell, the participant was asked: ' Could you now taste the wine and describe the flavor as precisely as possible? ' ( Wilt u nu de wijn proeven en de smaak zo precies mogelijk beschrijven? ). They then moved to the next stimulus until complete. The coffee flavor naming task was the same, with a familiarization phase, followed by describing the smells and then the flavors.
After the wine and coffee naming tasks, participants completed the two expertise questionnaires and odor awareness questionnaire, and then participated in the odor and taste naming tasks. For the odor naming task, each odor pen was uncapped by the experimenter and handed to the participant with the instruction: ' Can you describe the smell as precisely as possible? ' ( Kunt u de geur zo precies mogelijk beschrijven? ). For the taste naming task, participants were first warned some of the sprays might taste unpleasant. The participants were instructed: ' Could you now spray the taste on your tongue, and describe what you taste? ' ( Wilt u nu de smaak op uw tong sprayen , en beschrijven wat u proeft? ). Participants were allowed to spray the tastant a second time if they wished. After each taste, participants drank some filtered water. All stimuli were presented in a fixed order within each block, and there was a delay of at least 20 seconds between them (following [60]). In practice, the interstimulus interval was between 30 and 35 seconds. The sessions took place in a well-lit, well-ventilated room. All answers were recorded using an audio-recorder.","file.pdf~Procedure~21"
"file.pdf","Data processing",22,"Data processing
Audio-recordings were transcribed, and coded separately for the smell and flavor of wine and coffee, the smell of odor stimuli, and taste of basic tastants. To recap, things that are codable in language should be (1) concise; (2) have dedicated terminology; (3a) be described consistently and (3b) correctly. We operationalized each of these measures as follows:
First, the length of the description was measured by counting the number of characters in the fully transcribed response. Short descriptions would indicate higher codability than longer descriptions.
Second, we coded the types of responses participants gave in order to test whether experts differed from novices in the strategies they used to describe smells and flavors. Three categories were identified: (1) Source-based terms, i.e., words referring to objects that could emit that odor or flavor, e.g. kersen ' cherries ' , fruitig ' fruity ' ; (2) Evaluative terms, i.e., words describing hedonic evaluation, e.g., lekker ' pleasant ' , mooi ' nice ' , gadverdamme ' disgusting ' , and (3) Nonsource-based terms, i.e., words not referring directly to an object. This latter category is included following Majid and Burenhult [21] who identified a third category of abstract or ' basic ' terms. In Dutch this includes terms such as aromatisch ' fragrant/aromatic ' and muf ' musty ' . Participants rarely used this strategy; however, they did use other non-source-based descriptions such as cross-modal metaphors (e.g., zoet ' sweet ' , bitter ' bitter ' , groen ' green ' ),
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
7/21
Experts ' Flavor Naming
reference to a general state (e.g., gekookt ' cooked ' ), or associations with events or situations (e.g., winters ' wintery ' , bij de slager ' at the butcher ' ). We could, therefore, test whether experts and novices differed in the extent to which they gave evaluations, referred to a concrete source, or gave more abstract non-source-based descriptions.","file.pdf~Data processing~22"
"file.pdf","Data processing",23,"Data processing
Finally, we measured if speakers agreed in how they described smells and flavors. One way to operationalize this is in terms of naming accuracy. This is applicable to basic odors and tastes for which a correct or veridical answer could be said to exist. But this does not apply to the wines and coffees, since descriptions for these refer to components of the smell and flavor profile, and there is no ' correct ' answer. Therefore for the wines and coffees, we calculated whether participants agreed with one another in their descriptions [21,51]. To do this, the main responses from the fully transcribed descriptions were identified. For example, a speaker gave the description for a wine displayed in Box 1.
From this description the main qualitative descriptors kersen ' cherries ' , amarena kersen ' amarena cherries ' , tannines ' tannins ' , bitter ' bitter ' , mooi ' nice ' , and houtlagering ' wood aging ' were coded. Modifiers and hedges were ignored unless their exclusion changed the quality description. For example, licht ' light ' in lichte tannines ' light tannins ' was not coded since light only indicates the strength of the taste (or confidence of the participant). But amarena kersen ' amarena cherries ' was coded as a whole response including amarena , because amarena cherries may have a different quality of smell than generic cherries. Repeated responses (e.g., when a person mentioned kersen twice, as in the example above) were only coded once. Once the main responses were identified, the consistency between speakers was calculated using Simpson ' s Diversity Index [61], a measure of diversity in a given population, or in this case, diversity of words, following Majid and Burenhult [21]. For the odor stimuli and basic tastants, where ' correctness ' can be determined, both agreement and accuracy were measured. Accuracy was measured by calculating the percentage of veridical answers.","file.pdf~Data processing~23"
"file.pdf","Are wines and coffees more codable for wine experts and coffee experts?",24,"Are wines and coffees more codable for wine experts and coffee experts?
Length. Items that are highly codable typically receive more concise descriptions. Is this true for how wine and coffee experts describe wines and coffees? To test this, a mixed ANOVA with expertise (wine experts, coffee experts, novices) and naming task (wine smell, wine flavor, coffee smell, coffee flavor) was conducted, separately over participants ( F1 ) and items ( F2 ).
Box 1. Example of a Dutch wine expert ' s description for the taste of Wine 4, the Vallon des Sources Vacqueyras from France.
Emkersen in de mond. Kersen, ja amarena kersen daar gaat het naartoe. Lichte tannines, beetje bitter, maar mooi. Denk dat hij wel wat houtlaging heeft gehad maar niet overheersend.
Em, cherries in the mouth. Cherries, yes, amarena cherries that ' s what it ' s heading off to. Light tannins, a little bit bitter, but nice. I think he had some wood aging, but it ' s not overpowering.
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
8/21
Experts ' Flavor Naming","file.pdf~Are wines and coffees more codable for wine experts and coffee experts?~24"
"file.pdf","Are wines and coffees more codable for wine experts and coffee experts?",25,"Are wines and coffees more codable for wine experts and coffee experts?
Overall, participants had more to say about the flavors than smells of wines and coffees, F1 (3, 180) = 22.87, p < .001, η p² = .28; F2 (3, 16) = 34.96, p < .001, η p² = .87. In addition, wine experts talked more than novices, who in turn talked more than coffee experts, F1 (2, 60) = 3.68, p = .031, η p² = .11; F2 (2, 32) = 75.29, p < .001, η p² = .83. There was also an interaction between expertise and naming task, F1 (6, 180) = 4.50, p < .001, η p² = .13; F2 (6, 32) = 12.75, p < .001, η p² = .71. Contrary to the prediction, wine experts said more about the smell of wine ( M = 307, SD = 213) than coffee experts ( M = 156, SD = 136), p = .008, d = .85, but not more than novices ( M = 232, SD = 203), p = .375. The same pattern was found for the flavor of wine: wine experts ( M = 423, SD = 200) gave longer descriptions than coffee experts ( M = 223, SD = 129), p = .001, d = 1.18, but their descriptions did not differ from novices ( M = 322, SD = 220), p = .139. Turning to coffee, there were no significant differences in the length of the smell descriptions between coffee experts ( M = 160, SD = 115), wine experts ( M = 205, SD = 161) or novices ( M = 215, SD = 185), all ps > .05. The same pattern was found for the flavor descriptions of coffee; again there was no difference between coffee experts ( M = 270, SD = 132), wine experts ( M = 301, SD = 154) or novices ( M = 261, SD = 170), all ps > .05. So, wine experts said more about wines than the other groups, but coffee experts said the same amount as wine experts and novices about coffees, and were more succinct in general.","file.pdf~Are wines and coffees more codable for wine experts and coffee experts?~25"
"file.pdf","Are wines and coffees more codable for wine experts and coffee experts?",26,"Are wines and coffees more codable for wine experts and coffee experts?
Strategy. Did the groups rely equally on evaluative, source-based, and non-source-based terms? The answer is no (see Fig 1). Descriptions for the smell χ 2 (4, N = 1115) = 21.80, p < .001, Cramer ' s V = .10, and flavor χ 2 (4, N = 1378) = 37.80, p < .001, Cramer ' s V= .12 of wine depended on expertise. Wine experts used fewer non-source-based terms (e.g., chemisch ' chemical ' ) for wine smells z = -3.0, p = .001, while coffee experts and novices used more non-sourcebased terms, z = 1.8, p = .036, and z = 2.0, p = .023, respectively. Wine experts also used more source-based descriptors (e.g., vanille ' vanilla ' ) for wine flavors z = 1.8, p = .036, and fewer non-source-based terms, z = -2.4, p = .008. Coffee experts used fewer evaluative terms for wine flavors z = -2.6, p = .005, while novices used more z = 3.4, p < .001. Novices also used fewer source-based descriptors for wine flavors z = -2.5, p = .006 than either the wine or coffee experts. So, overall, wine experts used more source-based descriptions to describe the smells and flavors of wines; coffee experts used fewer evaluative terms for wine flavor; while overall, novices used more evaluative descriptions.","file.pdf~Are wines and coffees more codable for wine experts and coffee experts?~26"
"file.pdf","Are wines and coffees more codable for wine experts and coffee experts?",27,"Are wines and coffees more codable for wine experts and coffee experts?
For coffee smells there was no significant difference in description strategy χ 2 (4, N = 891) = 5.24, p = .263, Cramer ' s V = .05, but there was for coffee flavor χ 2 (4, N = 1097) = 22.61, p < .001, Cramer ' s V = .10. Just like the wine experts with wines, coffee experts gave significantly more source-based descriptors for coffees z = 2.0, p = .023. They also appeared to give fewer evaluative terms z = -1.6, p = .060, and non-source-based terms z = -1.6, p = .060. Similarly, novices gave more evaluative descriptors z = 2.8, p < .001, and fewer source terms z = -1.6, p = .060, just as they did for wines.
Overall, then, experts gave more source-based, concrete descriptions for the smells and flavors of the stimuli for which they were expert. Novices, in contrast, appeared to rely more heavily on evaluative terms, especially to describe flavors.
Consistency. Do experts agree with one another more in how they describe wines and coffees? To test this, an expertise (wine experts, coffee experts, novices) by naming task (wine smell, wine flavor, coffee smell, coffee flavor) mixed ANOVA was conducted using Simpson ' s Diversity Index calculated over first responses. There was a main effect of expertise, showing wine experts were more consistent than coffee experts or novices, F (2, 12) = 17.69, p < .001, η p² = .75, and a main effect of task, with the smell and taste of wine and taste of coffee described more consistently than the smell of coffee, F (3, 36) = 3.27, p = .032, η p² = .21. More importantly, there was a significant interaction between expertise and naming task F (6, 22) = 2.76, p = .037, η p² = .43. Planned comparisons showed wine experts had higher agreement with each
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
9/21
Experts ' Flavor Naming","file.pdf~Are wines and coffees more codable for wine experts and coffee experts?~27"
"file.pdf","Are wines and coffees more codable for wine experts and coffee experts?",28,"Are wines and coffees more codable for wine experts and coffee experts?
Fig 1. Description strategies used by wine experts, coffee experts and novices. Overall, experts and novices overwhelmingly relied on sourcebased descriptions (orange). However, wine experts used relatively more source-based terms to describe the smell and flavor of wine, and coffee experts used relatively more source-based terms to describe the flavor of coffee. Novices used more evaluative terms than the experts (black) to describe the smell and flavor of both coffee and wine.
doi:10.1371/journal.pone.0155845.g001
other when describing the smell of wine ( M = 0.09, SD = 0.05) than novices ( M = 0.03, SD = 0.012), p = .037, d = 1.65, but there was no significant difference between wine experts and coffee experts ( M = 0.04, SD = 0.02), p = .112. However, when describing the flavor of wine, wine experts had higher agreement ( M = 0.09, SD = 0.03) than novices ( M = 0.05, SD = 0.02), p = .011, d = 1.56, and coffee experts ( M = 0.04, SD = 0.02), p = .007, d = 1.96. In contrast, coffee experts did not agree more when describing the smell of coffee ( M = 0.04, SD = 0.02) than novices ( M = 0.03, SD = 0.01) or wine experts ( M = 0.03, SD = 0.02), p > .05. In fact, they agreed less ( M = 0.03, SD = 0.005) than the wine experts ( M = 0.09, SD = 0.02) about the flavor of coffee, p = .025, d = 4.11. The results revealed no significant differences between coffee experts and novices, p = .237, nor between novices and wine experts, p = .717 for the flavor of coffee (see Fig 2). So while wine experts are more consistent in how they describe the smells and flavors of wines, coffee experts are not. This suggests expertise only has a limited role to play in linguistic codability.","file.pdf~Are wines and coffees more codable for wine experts and coffee experts?~28"
"file.pdf","Are wines and coffees more codable for wine experts and coffee experts?",29,"Are wines and coffees more codable for wine experts and coffee experts?
The previous analysis only considered agreement on first responses. However, the analyses of description length earlier demonstrated the groups differed in the length of their descriptions. For example, wine experts described wines more elaborately than both other groups. When wine experts talk more, do they identify and name components that were identified by other experts? Or do the longer descriptions diverge more from one another? Taking all responses into account, there remained a main effect of naming task, F (3, 36) = 12.47, p < .001, η p² = .51, but not of expertise, F (2, 12) = 1.75, p = .215. There was an interaction between task and expertise, F (6, 22) = 3.19, p = .020, η p² = .47. Wine experts no longer showed more agreement on the smells of wines ( M = 0.02, SD = 0.001) than coffee experts ( M = 0.018,
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
10 / 21
Experts ' Flavor Naming
Fig 2. Agreement between experts and novices for wines and coffees. Wine experts were more consistent with each other in how they described the smell and flavor of wines than novices and coffee experts. In contrast, coffee experts were not more consistent than wine experts and novices for the smells and flavors of coffees. Letters indicate significant differences between groups; error bars represent ± 1 standard error.
doi:10.1371/journal.pone.0155845.g002","file.pdf~Are wines and coffees more codable for wine experts and coffee experts?~29"
"file.pdf","Are wines and coffees more codable for wine experts and coffee experts?",30,"Are wines and coffees more codable for wine experts and coffee experts?
SD = 0.004), p = .822 or novices ( M = 0.02, SD = 0.007), p > .05, nor did they show more agreement for the flavors of wines ( M = 0.018, SD = 0.004) than coffee experts ( M = 0.018, SD = 0.004), p > .05, or novices ( M = 0.014, SD = 0.005), p > .05. So, talking more does not seem to increase the likelihood of converging on descriptions of smell and flavor. However, when considering all responses coffee experts showed more agreement on the smell of coffee ( M = 0.02, SD = 0.003) than wine experts ( M = 0.01, SD = 0.003), p = .033, d = 3.33, but not more than novices ( M = 0.012, SD = 0.004), p = .302; nor did the novices differ from wine experts, p = .737. But similar to the analysis for the first responses, coffee experts agreed significantly less on the taste of coffee ( M = 0.012, SD = 0.002) compared to novices ( M = 0.025, SD = 0.005), p < .001, d = 3.4, and wine experts ( M = 0.025, SD = 0.004), p = .001, d = 4.11.","file.pdf~Are wines and coffees more codable for wine experts and coffee experts?~30"
"file.pdf","Are wines and coffees more codable for wine experts and coffee experts?",31,"Are wines and coffees more codable for wine experts and coffee experts?
Taken together, the results lend some support to the proposal that experts have higher codability for smells and flavors. But this agreement is rather limited in nature. Wine experts showed higher consistency when describing the smells of wines than novices, and when describing the flavor of wine and coffees than coffee experts. This suggests the wider linguistic and communicative experiences of wine experts may play a critical role for describing smells and flavors, since they perform even better than the coffee experts. However, this main effect is modulated by an interaction revealing domain-specific expertise. Wine experts agree with one another more about the smells and flavors of wines, but only when considering their first responses. When considering all responses, however, this agreement seems to disappear, possibly because each expert is isolating different components of the wine and coming to a unique linguistic profile for their experience. Coffee experts, on the other hand, only showed more
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
11 / 21
Experts ' Flavor Naming
agreement on the smells of coffees when taking all responses into consideration. Neither group showed a general advantage over novices across domains. So, it seems there is only a modest role of expertise when communicating about the smells and flavors of wines and coffees.
It is surprising that coffee experts show significantly less consistency for describing coffee flavors, considering describing these flavors is their core business. To better understand why this might be, we visualized the descriptions using word clouds (Fig 3 and Fig 4). In a word cloud, the relative size of a word indicates its relative frequency, with the largest words being the most frequent. The word clouds were made using the R package wordcloud [62]. It is clear from Fig 3 that wine experts and novices primarily described the coffees as bitter ' bitter ' or zuur ' sour ' . And as was demonstrated by the earlier analyses, novices described items as aangenaam ' pleasant ' or onaangenaam ' unpleasant ' . In contrast, coffee experts picked out specific flavors using source-based terms (such as chocolade ' chocolate ' , bessen ' berries ' , kruiden ' herbs ' ). They also identified sour and bitter components, but intriguingly their most frequent taste descriptor for the same coffees was zoet ' sweet ' .","file.pdf~Are wines and coffees more codable for wine experts and coffee experts?~31"
"file.pdf","Are wines and coffees more codable for wine experts and coffee experts?",32,"Are wines and coffees more codable for wine experts and coffee experts?
Acomparison across the five coffees showed wine experts and novices barely distinguished between the different coffees in their descriptions, while the coffee experts identified distinct flavor profiles. For example, Coffee 4, a Brazilian Yellow Bourbon, was described by the coffee experts as ' sweet ' , ' chocolate ' , ' balanced ' , and as having ' acidity ' . This parallels the descriptors given by an independent coffee expert in a non-blind tasting: ' known for its good balance between acidity, body and sweetness and for its excellent aftertaste. ' [63]. Similarly, Coffee 5, a Costa Rican Villa Sarchï, was described as having ' fruit ' , ' sweet ' , and ' acidity ' , again paralleling a non-blind tasting: ' Fruit acidity that ' s very clean; fruit driven sweetness that ' s intense. ' [64].
Fig 3. Word clouds of the 20 most frequent terms for coffee flavors. Wine experts and novices agreed more in their descriptions and predominantly describing all coffees as bitter and sour . Coffee experts, on the other hand, gave distinct flavor profiles to each coffee.
doi:10.1371/journal.pone.0155845.g003
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
12 / 21
Fig 4. Word clouds of 20 most frequent descriptors for wine flavors. Wine experts agreed on two main qualities: fruit and whether the wine contained tannins . In addition, they identified further distinctive qualities in their descriptions. Novices commented on a number of taste qualities (e.g., zuur ' sour ' , droog ' dry ' , wrang ' tart ' , bitter ' bitter ' ), and gave evaluative descriptions (e.g., aangenaam ' pleasant ' ).
Experts ' Flavor Naming","file.pdf~Are wines and coffees more codable for wine experts and coffee experts?~32"
"file.pdf","Are wines and coffees more codable for wine experts and coffee experts?",33,"Are wines and coffees more codable for wine experts and coffee experts?
To see whether wine experts also distinguished between the different wines, the same analysis was repeated for the flavor of wine (Fig 4). Interestingly, wine experts described the flavor of all five wines fairly similarly, by using the source-based descriptor fruit ' fruit ' . They also commented on the presence or absence of tannine ' tannins ' , noted zuur ' sour ' , droog ' dry ' , and used specific source-based descriptors, e.g. kers , ' cherry ' , braam ' blackberry ' , and vanille ' vanilla ' .
Summary. Experts used different linguistic strategies to describe their domain of expertise. Wine experts had more to say about the smell and flavor of wine, and had higher consistency in their first descriptions. Coffee experts, on the other hand, only showed higher agreement on the smells of coffees when considering their full responses. Despite these differences, both expert groups relied more on source-based descriptions to describe the stimuli from their expert domain, while novices took a more evaluative stance.
Although coffee experts did not show higher levels of agreement in their descriptions of coffee tastes, their responses appear to be more distinctive for each type of coffee than wine experts ' or novices ' . In fact, their descriptions provided when blind-tasting coffees overlapped considerably with expert coffee descriptions from a non-blind tasting. This suggests although coffee experts did not show higher agreement, they nevertheless were distinctive in their linguistic descriptions. A parallel analysis of the wine experts ' descriptions of wine showed the wine experts agreed on the same two main characteristics for all the wines, and that some coffee experts and novices recognized those too, albeit to a lesser extent.","file.pdf~Are wines and coffees more codable for wine experts and coffee experts?~33"
"file.pdf","Do experts have an advantage in naming basic smells and tastes?",34,"Do experts have an advantage in naming basic smells and tastes?
To further test the domain-specificity of linguistic descriptions of smells and tastes, we tested experts and novices on simple everyday odors (e.g., cinnamon, lemon) and tastes (e.g., sweet,
passen
doi:10.1371/journal.pone.0155845.g004
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
13 / 21
Experts ' Flavor Naming
Fig 5. Correct responses for smell and taste stimuli. There was no significant difference between groups in the percentage of correctly named smells or tastes. Error bars represent ± 1 standard error.
doi:10.1371/journal.pone.0155845.g005
sour), as well. We first consider whether there was a general expertise advantage for smells and then tastes.
Odor naming task. Length: Do experts give more concise descriptions for smell stimuli outside their domain of expertise? A one-way ANOVA comparing the different groups on the number of characters in the descriptions showed an effect of expertise F1 (2, 62) = 2.61, p = .082, η ² = .08, F2 (2, 27) = 12.71, p = .001, η ² = .59. Coffee experts gave the shortest descriptions ( M = 102, SD = 103); significantly shorter than wine experts ( M = 146, SD = 125) p = .002, d = .38, and novices ( M = 144, SD = 127), p = .012, d = .36. Wine experts and novices did not differ from each other, however, p > 0.5.","file.pdf~Do experts have an advantage in naming basic smells and tastes?~34"
"file.pdf","Do experts have an advantage in naming basic smells and tastes?",35,"Do experts have an advantage in naming basic smells and tastes?
Strategy: Odors were described differently depending on expertise, χ 2 (4, N = 1698) = 22.90, p < .001, Cramer ' s V = .08. Wine experts used more non-source-based terms z = 2.2, p = .015, while coffee experts used them less frequently z = -2.0, p = .025. In contrast, coffee experts used more source-based terms, z = 1.8, p = .036. In addition, coffee experts also used fewer evaluative terms z = -2.3, p = .010, while novices used more, z = 1.9, p = .029.
Agreement: Comparing agreement using Simpson ' s Diversity Index showed no significant effect for expertise in either first F (2, 29) = .90, p = .417, η ² = .06 or all responses F (2, 29) = 1.25, p = .302, η ² = .09.
Accuracy: We also compared the percentage of correct answers in the full descriptions. There was no difference between groups F1 (2, 62) = .07, p = .936, η ² = .01, F2 (2, 28) = .40, p = .677, η ² = .04 (see Fig 5).
Taste naming task. Length: There was a significant effect of expertise on length F1 (2, 62) = 3.24, p = .046, η ² = .10; F2 (2, 14) = 24.82, p = .002, η ² = .78. Wine experts ( M = 113, SD = 18) and novices ( M = 112, SD = 31) gave descriptions of the same length, p = .964, d = .01. However, coffee experts gave significantly shorter descriptions ( M = 67, SD = 19) than novices, p= .002, d = 2.51, and wine experts, p = .003, d = 1.76.
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
14 / 21
Experts ' Flavor Naming","file.pdf~Do experts have an advantage in naming basic smells and tastes?~35"
"file.pdf","Do experts have an advantage in naming basic smells and tastes?",36,"Do experts have an advantage in naming basic smells and tastes?
Strategy: The groups differed in the linguistic strategy used to describe tastes, χ 2 (4, N = 1496) = 16.91, p = .002, Cramer ' s V = .08. Coffee experts used significantly fewer evaluative terms z = -2.6, p = .005 than the wine experts or the novices. No other word type frequencies were statistically different from the expected model.
Agreement: There was no difference between groups in agreement in first responses, F (2, 23) = 1.49, p = .249, η ² = .12. However, there was an effect of group when considering all descriptions F (2, 23) = 16.46, p < .001, η ² = .61. Coffee experts agreed with one another more in how to describe basic tastes ( M = 0.23, SD = 0.06) than wine experts ( M = 0.14, SD = 0.04), p = .001, d = 1.77, and novices ( M = 0.12, SD = 0.02), p < .001, d = 2.46, while novices and wine experts did not differ from each other, p = .107.
Accuracy: There was no difference between the groups in the percentage of correctly identified tastes in full descriptions F1 (2, 62) = .54, p = .584, η ² = .02, F2 (2, 14) = 3.01, p= .082, η ² = .30 (see Fig 5).
Summary. Overall, when describing everyday smells and basic tastes, wine experts appeared to talk the most, and coffee experts the least. Novices tended to give more evaluative responses for both smells and tastes than experts. Agreement and accuracy did not differ between groups, apart from a slight advantage for naming basic tastes by coffee experts, when all responses were considered. This may have to do with the fact that coffee experts ' are trained to seek a coffee that is the perfect balance of bitter, sour, and sweet.","file.pdf~Do experts have an advantage in naming basic smells and tastes?~36"
"file.pdf","Discussion",37,"Discussion
The smell and flavor of wine and coffee seems to be described differently by wine and coffee experts in comparison to novices. Wine experts agreed more on the smell and flavor of wine, and this coincided with the use of more specific source-based terms compared to novices. Coffee experts used a similar strategy for the smell and flavor of coffee, and their descriptions were more succinct than those of novices. But this did not lead to higher agreement between the speakers for the smell and flavor of coffee. The results did not show a general influence of expertise on flavor naming. Differences in talk between wine and coffee experts, where apparent, only appear in their own domains of expertise. So, wine and coffee training only appears to play a limited role in how people talk about smells and flavors.","file.pdf~Discussion~37"
"file.pdf","Wine speak",38,"Wine speak
It was unclear from the prior studies whether wine experts really were better at describing the smells and flavors of wines than non-experts. Previous studies differed in the stimuli used to test the verbal abilities of wine experts, and in the criteria used to measure those descriptions. Some studies used simple odors [40,46], while other studies used wines [35,39,44]. Some studies examined the types of terms experts use [34,35,37,39], while others took more quantitative measures, such as agreement between speakers [46]. The present study combined these qualitative and quantitative approaches, to get a better understanding of what happens when flavor experts communicate about smells and flavors. We found wine experts talked more, and used more specific source-based terms to describe the smell and taste of wine, which converges with some previous findings [33 -35]. In addition, and contrary to other findings (cf. [46]), wine experts reached higher agreement than novices when describing wines.
In contrast to previous studies [28 -31], we found wine experts used very few metaphors. This could be because of the specific task we used. Tasting notes on websites and in magazines written by wine experts serve an entertainment, or literary function in addition to giving information about wine. Examination of these materials tends to show an enhanced reliance on metaphor. In this experiment, participants were asked to give descriptions as precisely as
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
15 / 21
Experts ' Flavor Naming
possible, which did not encourage (nor discourage, particularly) metaphorical constructions. This context is comparable to how wine experts communicate during ' tastings ' , or when they sell wines to consumers face-to-face. In this context, experts seem to rely on more concrete vocabulary.","file.pdf~Wine speak~38"
"file.pdf","Wine speak",39,"Wine speak
One notable aspect in this study was the different linguistic behavior of wine and coffee experts. This difference between groups of experts is surprising given that a previous study [40] revealed no apparent differences in smell descriptions between flavor experts. In the present study, wine experts were verbose and agreed on the descriptions for wine; the coffee experts were overall more succinct. These differences in descriptions in the present study are unlikely to be caused by intrinsic properties of the stimuli, as the wines and coffees were sorted in comparable ways by novice participants in a control study. Both groups were also comparable in amount of expertise. Wine and coffee experts were both professionals, earning their living with their knowledge. These criteria were independently confirmed by the expertise questionnaires. Moreover, the odor awareness questionnaire showed both expert groups were equally aware of odors in daily life (and more so than the novices). So the differences between expert groups are unlikely to be due to these factors.
Instead we suggest wine experts differ from coffee experts because of the different language games surrounding these two industries. While ' wine talk ' is an attested genre, there is little comparable ' coffee talk ' (i.e., about coffee, rather than over coffee). As we suggested in the introduction, wine experts have more opportunities to read, listen, and talk about the smells and flavors of wines (e.g., in magazines, menus, tastings, etc.), than coffee experts do for coffees. This means the two expert groups are doing different things when communicating about smells and flavors in their daily life. As Silverstein [65] suggests, wine experts are arguably indexing how much they know about the wines, as much as they are describing the properties of the wine itself.","file.pdf~Wine speak~39"
"file.pdf","Codability",40,"Codability
Wehad asked whether smells and flavors were linguistically expressed more easily by experts than novices. Linguistic expressibility is a complex notion that can be operationalized in various ways (cf. [13]). We focused on length of description, types of responses, agreement between speakers and accuracy, following the classic work of Brown and Lenneberg [21,51]. They [51] asked English speakers to name colors and found exactly those colors with concise descriptions also had short reaction times, and within- and across-speaker agreement. They then derived a single composite measure of linguistic ' codability ' , combining these measures, and found color chips with high codability were also remembered better. This suggests differential linguistic coding can have wider impact on memory and perception, a proposal that has recently found further support in the domain of color, for example [66 -69].
Our results did not show the same alignment of length and agreement found in these earlier studies. Wine experts had higher agreement yet gave longer descriptions, while coffee experts gave short descriptions but did not agree. So, perhaps this way of examining the linguistic behavior of experts needs to be reconsidered. It seems as if length is not a diagnostic measure in this study, since longer talk appears to index the speaker ' s orientation, rather than indicate how difficult the entity was to describe. More importantly, earlier studies (which have found length to coincide with agreement) have asked speakers to name stimuli, rather than describe them. In sum this suggests agreement is likely the more informative measure in our study. On this measure we find a small advantage for experts when describing stimuli from their own domain of expertise.
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
16 / 21
Experts ' Flavor Naming","file.pdf~Codability~40"
"file.pdf","Codability",41,"Codability
Across the board, people tended to use source-based descriptions (e.g., berry , vanilla) , but both expert groups tended to use more such descriptions in their domain of expertise. It appears that expert descriptions may be more informative. Compare a coffee expert ' s descriptions for coffee number five -e.g., ' a fruity, acidic coffee with a fermented aroma and hints of caramel, honey and citrus '-with a novice ' s -e.g., ' a sour and unpleasant coffee with some hints of berry ' , for example. In order to verify this, future studies could also examine whether people find it easier to understand expert descriptions than novices ' , by conducting a directormatcher task, where people have to match wines and coffees to descriptions (cf. [38]). Some previous work, indeed, suggests descriptions from experts are better matched to the original stimulus than those produced by novices [35, 44, 70]. Our current results indicate there may be differences depending on the expert and the domain. It would be interesting to examine whether wine and especially coffee expert descriptions are equally informative when given to other experts or novices.
Finally, prior research in other domains (e.g., color) shows a tight link between linguistic coding and memory, which raises the question whether expert memory might also be linguistically mediated. Some studies have found wine experts ' recognition memory to be superior to that of novices ' [37,39,46,71], although a link between experts ' language use and recognition memory has not been reliably demonstrated. This is a matter for future research.","file.pdf~Codability~41"
"file.pdf","Culture and sub-culture",42,"Culture and sub-culture
For wine and coffee experts, smells and flavors play an important role in their daily routine, and experts can be seen as part of a sub-culture, with specific practices revolving around smell and flavor [25]. One explanation for the finding wine experts are better at describing the smells and flavors of wine is that wine experts often engage in talk about wine (cf. [26]), which trains them use language in a specific way. This suggests that to become better at describing smells and flavors, not only is it important to have abundant perceptual experience (cf. [52, 72]), but also to train verbalizing these experiences.
Yet another possibility to explain the differences between wine and coffee experts lies in the way these experts appreciate wine and coffee, respectively. During a normal wine tasting or judgment session, wine experts first note the color, before the wine is smelled (cf. [25]). Smelling is sometimes composed of two parts, where the wine is first smelled when it rests still in the glass, and second when the glass is swirled to release additional aromas. Flavor appreciation comes after this, where among other things, experts pay attention to how sweet or dry a wine is, what mouthfeel it produces, and how long the aftertaste lingers.","file.pdf~Culture and sub-culture~42"
"file.pdf","Culture and sub-culture",43,"Culture and sub-culture
Coffee experts approach coffee judgments during cupping in a slightly different manner. As with the wine experts, coffee experts first note the color of the ground coffee. But for the coffee experts, the smelling component of cupping is divided into three parts: first the dry, freshly ground coffee is smelled (the so-called ' fragrance of the coffee ' ). Water is then poured on the coffee. The ' crust ' that has formed on top of the coffee is then ' broken ' by stirring it gently with a spoon. The aroma of the coffee is smelled at this stage too. Finally, after the coffee has steeped for a while, the aroma of the coffee is judged a final time. The three orthonasal parts are combined in a single aroma quality judgment. The coffee is then tasted from a spoon, to get as much air as possible with the coffee sample in the mouth. During this stage, coffee experts, similar to wine experts, pay attention to how sweet the coffee is, what (retronasal) flavors are in the sample, etc. [54]. In the present study, to make the tasks and subsequent data more comparable across the two domains, participants were only able to smell the coffee when it had already steeped for some time. It could be the case that coffee experts would achieve higher agreement were they to smell and describe during these other phases. Future studies specifically
PLOSONE|DOI:10.1371/journal.pone.0155845 June 20, 2016
17 / 21
Experts ' Flavor Naming
investigating coffee expertise are required in order to test coffee experts ' abilities to describe the various aspects of orthonasal coffee olfaction.
Overall, however, the main expert advantage we found was when wine experts described stimuli from their own domain of expertise. In contrast, the Jahai are better in describing smells regardless the domain or category the smell comes from [21]. An indirect comparison of the present study to the study by Majid and Burenhult [21] appears to indicate Jahai speakers have higher codability for smells they have never encountered before than wine experts have for smells from sources encountered every day. Even after many years of experience, experts do not appear to show the linguistic prowess for smells the Jahai have. Why might this be so?","file.pdf~Culture and sub-culture~43"
"file.pdf","Culture and sub-culture",44,"Culture and sub-culture
There are at least two possible explanations. First, there may be some genetic difference between Jahai speakers and Western speakers that enables the Jahai to talk about smells with relative ease. There are wide-spread differences between populations in olfactory genes [73,74], and different sensitivity for specific odorants [75]. In addition, populations differ in olfactory discrimination [76 -78].
Asecond possibility has to do with the age of acquisition of smell and flavor vocabularies. Children with different cultural backgrounds are socialized in different ways with regard to the senses, and in some communities children are taught smell is an important part of the world (cf. [79]). In particular, Jahai speakers learn smell vocabulary as children as part of normal language acquisition, unlike wine and coffee experts. Training for experts does not begin until they are adults, long past any critical period for language acquisition. It could be the wine and coffee experts simply cannot overcome this maturational limitation.","file.pdf~Culture and sub-culture~44"
"file.pdf","Conclusion",45,"Conclusion
In sum, it appears sensory experience and cultural preoccupation alone is not enough to overcome the boundaries of language. Wine and coffee experts have only a small advantage over novices when describing smells and flavors, limited to their domain of expertise. We suggest more emphasis needs to be given to the verbal practices around smells and flavors, in addition to aspects surrounding expert perceptual training. After all, in order to decide what wine or coffee to buy, or to choose a food and drink pairing, or simply to convey our aesthetic appreciation, we use language. Our perceptual experiences are shared through our common tongue.
To conclude, perceptual experience alone is not enough to overcome the boundaries of language; verbal training is also essential in order to effectively communicate about smells and flavors.","file.pdf~Conclusion~45"
"file.pdf","Acknowledgments",46,"Acknowledgments
This work was funded by The Netherlands Organization for Scientific Research: NWO VICI grant ' Human olfaction at the intersection of language, culture and biology ' . Special thanks go to Michiel Buijs, Rose van Asten, Liesbeth Sleijster, Josje de Valk and Nina Krijnen for help with the study.","file.pdf~Acknowledgments~46"
"file.pdf","Author Contributions",47,"Author Contributions
Conceived and designed the experiments: IC AM. Performed the experiments: IC. Analyzed the data: IC AM. Contributed reagents/materials/analysis tools: IC. Wrote the paper: IC AM.","file.pdf~Author Contributions~47"
"s13428-019-01316-z.pdf","78X",1,"1291
https://doi.org/10.3758/s13428-019-01316-z Behavior Research Methods (2020) 52:1271 -","s13428-019-01316-z.pdf~78X~1"
"s13428-019-01316-z.pdf","The Lancaster Sensorimotor Norms: multidimensional measures of perceptual and action strength for 40,000 English words",2,"The Lancaster Sensorimotor Norms: multidimensional measures of perceptual and action strength for 40,000 English words
Dermot Lynott 1 & Louise Connell 1 & Marc Brysbaert 2 & James Brand 1,3 & James Carney 1,4
# The Author(s) 2019
Published online: 12 December 2019","s13428-019-01316-z.pdf~The Lancaster Sensorimotor Norms: multidimensional measures of perceptual and action strength for 40,000 English words~2"
"s13428-019-01316-z.pdf","Abstract",3,"Abstract
Sensorimotor information plays a fundamental role in cognition. However, the existing materials that measure the sensorimotor basis of word meanings and concepts have been restricted in terms of their sample size and breadth of sensorimotor experience. Here we present norms of sensorimotor strength for 39,707 concepts across six perceptual modalities (touch, hearing, smell, taste, vision, and interoception) and five action effectors (mouth/throat, hand/arm, foot/leg, head excluding mouth/throat, and torso), gathered from a total of 3,500 individual participants using Amazon ' s Mechanical Turk platform. The Lancaster Sensorimotor Norms are unique and innovative in a number of respects: They represent the largest-ever set of semantic norms for English, at 40,000 words × 11 dimensions (plus several informative cross-dimensional variables), they extend perceptual strength norming to the new modality of interoception, and they include the first norming of action strength across separate bodily effectors. In the first study, we describe the data collection procedures, provide summary descriptives of the dataset, and interpret the relations observed between sensorimotor dimensions. We then report two further studies, in which we (1) extracted an optimal singlevariable composite of the 11-dimension sensorimotor profile (Minkowski 3 strength) and (2) demonstrated the utility of both perceptual and action strength in facilitating lexical decision times and accuracy in two separate datasets. These norms provide a valuable resource to researchers in diverse areas, including psycholinguistics, grounded cognition, cognitive semantics, knowledge representation, machine learning, and big-data approaches to the analysis of language and conceptual representations. The data are accessible via the Open Science Framework (http://osf.io/7emr6/) and an interactive web application (https://www. lancaster.ac.uk/psychology/lsnorms/).
My whole body remembered it, the familiar scrape of stone against my palm, the brace of my thigh muscle as I pushed myself upwards, into the whirl of green and exploding light. -Tana French 2007, In the Woods , p. 589
* Dermot Lynott d.lynott@lancaster.ac.uk
* Louise Connell l.connell@lancaster.ac.uk","s13428-019-01316-z.pdf~Abstract~3"
"s13428-019-01316-z.pdf","Abstract",4,"Abstract
1 Department of Psychology, Lancaster University, Lancaster, UK
2 Department of Experimental Psychology, Ghent University, Ghent, Belgium
3 New Zealand Institute of Language Brain and Behaviour, University of Canterbury, Canterbury, New Zealand
4 Department of Arts and Humanities, Brunel University London, London, UK
Sensorimotor information is central to how we experience and navigate the world. We acquire information through our senses, while our bodies provide feedback, as we physically interact with objects, people, and the wider environment. Many theoretical views of cognition describe a fundamental role for such sensorimotor knowledge in conceptual thought (e.g., Barsalou, 1999; Connell, 2019; Connell & Lynott, 2014b; Smith & Gasser, 2005; Vigliocco, Meteyard, Andrews, & Kousta, 2009; Wilson, 2002), with numerous empirical demonstrations supporting such claims (e.g., Connell, Lynott, & Dreyer, 2012; Kaschak, Zwaan, Aveyard, & Yaxley, 2006; Matlock, 2004; Zwaan & Taylor, 2006).
To test such embodied (or grounded) theories of cognition, researchers need appropriate stimuli for empirical tests and for developing mathematical or computational models. Lynott and Connell (2009, 2013) developed a set of modalityspecific sensory norms for concepts for which each sensory modality (e.g., auditory, gustatory, haptic, olfactory, or visual) maps onto distinct cortical regions (e.g., gustatory cortex,
1272","s13428-019-01316-z.pdf~Abstract~4"
"s13428-019-01316-z.pdf","Abstract",5,"Abstract
auditory cortex, etc.). By having individuals provide ratings for each modality separately, the norms capture the extent to which something is experienced across different sensory modalities, without risk of ignoring or distorting the role of particular modalities (Connell & Lynott, 2012a, 2016a). Subsequent empirical studies have shown that such modality-specific measures are good predictors of people ' s performance across a range of cognitive tasks (e.g., lexical decision, word naming, and property verification), and often outperform long-established measures such as concreteness and imageability (e.g., Connell & Lynott, 2012a, 2014a). For example, in examining performance on lexical decision and word-naming (reading-aloud) tasks, Connell and Lynott (2012a) found that modality-specific experience (specifically, the extent of perceptual experience in the strongest modality for a given concept, its ' maximum perceptual strength ' ) was a more reliable predictor of performance than both concreteness and imageability. Closer analysis showed that concreteness ratings appeared to capture separate decision criteria, and some modality-specific information was either ignored or skewed by raters. Moreover, imageability ratings were heavily biased toward the visual modality at the expense of other modalities. Connell and Lynott (2016a) also found that when people are asked to rate sensory experience generally (as opposed to focusing on one modality at a time), it can lead to extensive loss of information (e.g., modality-specific auditory, gustatory, and haptic information was neglected by people, whereas information from olfactory and visual dimensions was distorted). Critically, this information loss was reflected in weaker semantic facilitation in word recognition, a phenomenon that results from automatic and implicit access to the grounded representation of a word ' s meaning: maximum perceptual strength derived from modality-specific measures outperformed overall sensory experience ratings (Juhasz & Yap, 2013) in predicting latency and accuracy of lexical decision judgments. These findings highlight the importance of individually rating separate perceptual modalities when norming the sensory basis of words and concepts.","s13428-019-01316-z.pdf~Abstract~5"
"s13428-019-01316-z.pdf","Abstract",6,"Abstract
An added advantage of using modality-specific measures of sensory experience is that they allow researchers to tap into effects that relate to particular modalities and not others. Connell and Lynott (2010) showed how a processing disadvantage for tactile stimuli observed during perceptual processing was also observed when processing modality-specific words. That is, in perception, people are poorer at detecting tactile stimuli relative to auditory and visual stimuli (Spence, Nicholls, & Driver, 2001). Using a signal detection paradigm, Connell and Lynott (2010) found that people were similarly poorer at detecting tactile-related words (e.g., sticky ) relative to other modalities. Connell and Lynott (2014a) also derived contrasting modality-specific predictions relating to lexical decision and reading aloud for individual words. Because lexical decision is a primarily visual task, it necessarily focuses
Behav Res (2020) 52:1271 -1291
attention on the visual system, and preallocation of attention to vision facilitates processing of semantic information related to the visual modality (e.g., Connell et al., 2012; Foxe, Simpson, Ahlfors, & Saron, 2005). Thus, for lexical decisions, Connell and Lynott (2012b, 2014a) found that strength of perceptual experience in the visual modality (but not the auditory modality) was a reliable predictor of performance in that task. By contrast, reading aloud also requires attention on the auditory modality, as participants must plan and monitor their speech output to ensure correctly articulated responses. Consistent with this idea, strength of auditory experience and strength of visual experience were both reliable predictors for performance for the reading aloud task. Such phenomena could not have been detected using extant measures (e.g., concreteness or imageability ratings) because they do not offer sufficient granularity in terms of perceptual experience. Thus, modalityspecific measures of sensory experience provide the capacity to generate and test novel predictions related to modalityspecific processing and representations.","s13428-019-01316-z.pdf~Abstract~6"
"s13428-019-01316-z.pdf","Abstract",7,"Abstract
The above work on perceptual strength concentrated on five common modalities of sensory experience: touch, hearing, smell, taste, and vision. More recently, however, Connell, Lynott, and Banks (2018) showed that interoception (i.e., sensations inside the body) also plays an important role in semantic representations, and could be a primary grounding mechanism for abstract concepts. As compared to more concrete concepts like banjo or rainy , strength of interoceptive experience was higher for abstract concepts like hungry and serenity , and was particularly important for emotion concepts such as fear and happiness . Moreover, including interoceptive strength in a measure of maximum perceptual strength enhanced semantic facilitation in lexical decision performance (as compared to the original set of five modalities). Overall, modality-specific measures of interoceptive experience seem to be just as important as measures from other perceptual modalities in capturing the sensory basis of semantic knowledge.
Since the original appearance of modality-specific norms of perceptual strength, interest in their broad utility has led other research groups to extend them in a variety of directions. Perceptual strength norms (also termed modality exclusivity norms, after the original Lynott & Connell, 2009, work) now exist in several different languages, including Russian (Miklashevsky, 2018), Serbian (Filipovi ć Đ ur đ evi ć , Popovi ć Stija č i ć , & Karapand ž i ć , 2016), Dutch (Speed & Majid, 2017), and Mandarin (Chen, Zhao, Long, Lu, & Huang, 2019), and have been developed for concept -property pairs as well as individual words (van Dantzig, Cowell, Zeelenberg, & Pecher, 2011). The original English-language norms have also been applied in novel ways, such as examining stylistic differences of authors (Kernot, Bossomaier, & Bradbury, 2019), studying perceptual metaphors (e.g., rough sound , smooth melody ; Winter, 2019), testing models of lexical
Behav Res (2020) 52:1271 -1291
1273","s13428-019-01316-z.pdf~Abstract~7"
"s13428-019-01316-z.pdf","Abstract",8,"Abstract
representations (Johns & Jones, 2012), evaluating the iconicity of words in written (Winter, Perlman, Perry, & Lupyan, 2017), and signed languages (Perlman, Little, Thompson, & Thompson, 2018), and discovering links between sensory and emotional experience (Winter, 2016).
Nonetheless, a notable gap in the work discussed above is that it focuses solely on sensory experience, and has not included parallel measures of action or effector-specific experience. However, there is good evidence for the relevance of action experience to people ' s semantic representations of concepts (e.g., Glenberg & Gallese, 2012; Hauk, Johnsrude, & Pulvermüller, 2004). For instance, manual action verbs such as throw activate some of the same motor circuits as moving the hand (Hauk et al., 2004), and their processing is selectively impaired in patients with Parkinson ' s disease, which entails neurodegeneration of the motor system (Boulenger, Hauk, & Pulvermüller, 2008; Fernandino et al., 2013). Critically, the motor basis to semantic knowledge is specific to the bodily effector used to carry out a particular action. Applying transcranial magnetic stimulation (TMS) to hand and leg areas of the motor cortex differentially influences processing of hand and leg action words: Hand area TMS facilitates lexical decision of hand action words, such as pick , relative to leg action words, such as kick , whereas this effect is reversed with leg area TMS (Pulvermüller, Hauk, Nikulin, & Ilmoniemi, 2005; see also Klepp et al., 2017). Such double dissociations in motor-language facilitation underscore the importance of individually examining separate action effectors when norming the motor basis of words and concepts.","s13428-019-01316-z.pdf~Abstract~8"
"s13428-019-01316-z.pdf","Abstract",9,"Abstract
Some existing measures have attempted to capture action knowledge, but have alternatively used feature production tasks, as opposed to rating dimensions of action (i.e., in which people verbally list the features associated with concepts: McRae, Cree, Seidenberg, & McNorgan, 2005; Vinson & Vigliocco, 2008), focused on generalized action (e.g., body -object interaction: Tillotson, Siakaluk, & Pexman, 2008; relative embodiment: Sidhu, Kwan, Pexman, & Siakaluk, 2014; see Connell & Lynott, 2016b, for review), or focused on a restricted subset of action types (e.g., graspability: Amsel, Urbach, & Kutas, 2012; actions associated with lower limb, upper limb, or head: Binder et al., 2016) that omits other parts of the body involved in action. For example, the action of pushing can also involve the torso (Moody & Gennari, 2010), and mouth actions are cortically distinct from other actions of the face (Meier, Aflalo, Kastner, & Graziano, 2008). To our knowledge, therefore, no large-scale set of norms taps into a comprehensive range of effector-specific action experience. In the present work, we address this gap by collecting effector-specific action strength norms for a large number of concepts.
Overall, there is good evidence for the internal reliability, face validity, and predictive value of existing modalityspecific measures of experience, but studies to date have been","s13428-019-01316-z.pdf~Abstract~9"
"s13428-019-01316-z.pdf","Abstract",10,"Abstract
hampered by their relatively small scale (typically a few hundred items). Because megastudies with tens of thousands of words are increasingly used across the cognitive sciences to enable greater statistical power, reduce experimenter bias in item selection, and increase study reliability (e.g., Balota, Yap, Hutchison, & Cortese, 2012; Brysbaert, Mandera, & Keuleers, 2018; Kuperman, Estes, Brysbaert, & Warriner, 2014), it has become essential to provide suitably large sets of norms. In the present study, we present sensorimotor norms across 11 dimensions for approximately 40,000 concepts, comprising six modality-specific dimensions of perceptual strength (auditory, gustatory, haptic, olfactory, visual, interoceptive) and five effector-specific dimensions of action strength (head, arm/hand, mouth, leg/foot, torso). Because the modality-specific measures of perceptual strength map to specific, separable regions of the somatosensory and insular cortex (e.g., Craig, 2003; Goldberg, Perfetti, & Schneider, 2006), so too do the effector-specific measures of action strength map to specific, separable regions of the motor cortex (e.g., Aflalo & Graziano, 2006).","s13428-019-01316-z.pdf~Abstract~10"
"s13428-019-01316-z.pdf","Abstract",11,"Abstract
To the best of our knowledge, these norms represent the largest ever set of semantic norms for English, and bring the following benefits. First, incorporating almost 40,000 words, they provide far greater lexical coverage than has been possible with previous norms, encompassing the majority of words known to an average adult speaker of English (i.e., approximating a full-size adult conceptual system; Brysbaert, Warriner, & Kuperman, 2014). Second, they extend existing norms to new sensory modalities (i.e., interoception), which have been found to be especially important for how people represent emotion-related concepts (Connell et al., 2018). Third, the norms go beyond perceptual strength to include action strength with a range of effectors that spans the full body, allowing researchers to consider a far greater range of object-related experiences, and to test effector-specific theoretical predictions. Fourth, with approximately 40,000 words × 11 dimensions (plus cross-dimensional variables), the scale of the norms also provides the statistical power for a wide range of applications, including examining complex relations between variables that provide sensorimotor grounding for concepts; identifying subtle, but potentially important, semantic effects and interactions in language processing; and using the norms in machine learning techniques such as document categorization.","s13428-019-01316-z.pdf~Abstract~11"
"s13428-019-01316-z.pdf","Method",12,"Method
From the main Open Science Foundation (OSF) project page for this project (https://osf.io/7emr6/), readers can access all materials and data; scripts for experiments and data analysis;
1274
and full results of analysis. Researchers can also access itemlevel norms via a web interface, located at https://www. lancaster.ac.uk/psychology/lsnorms/. In addition to the aggregated data, we also separately include full trial-level data from participants, also downloadable from the project ' s OSF page.
Materials Our original item set was a total of 39,954 English lemmas, comprising 37,058 single-word items (e.g., bus ) and 2,896 lexicalized two-word items (e.g., bus stop ). All items were taken from Brysbaert, Warriner, and Kuperman ' s (2014) work on concreteness ratings, which represented all lemmas known by at least 85% of native speakers of English, and used American English spellings. 1 The dataset contains words from major syntactic categories (e.g., nouns, verbs, prepositions, pronouns, adjectives, adverbs, etc.) and a wide range of concepts (e.g., foods, animals, emotions, sports, taboo words, professions, colors, etc.) We divided the total item set into 821 lists of 48 test items plus a constant set of five calibrator and five control words that appeared in all lists (see below). Thus, each list rated by participants consisted of 58 items. Following initial testing, 20 additional lists were created that had a different number of items (up to a maximum of 64 items) to include words that received only a low number of valid ratings when first tested, and some words that were missing from the original master list of words. All lists were created using the same criteria described below.","s13428-019-01316-z.pdf~Method~12"
"s13428-019-01316-z.pdf","Method",13,"Method
Five calibrator words were presented to participants at the start of each item list, in the same order, to introduce participants to unambiguous examples of items that spanned the full range of sensorimotor strength in different dimensions. We selected the calibrator words separately for perceptual and action strength norming from items that were 100% known in Brysbaert et al. ' s (2014) concreteness norms. For perceptual strength norming, the calibrator words were taken from existing norms (Lynott & Connell, 2009, 2013, plus other unpublished ratings available here: https://www.lancaster.ac. uk/staff/connelll/lab/norms.html) to have low variance in ratings across participants and to provide examples of the following criteria (calibrator word given in brackets): low strength across all modalities ( account ), medium strength across multiple modalities ( breath ), high strength in a single modality ( echo ), uneven strength across modalities ( hungry ), and high strength across multiple modalities ( liquid ). For motor strength norming, the calibrator words were selected according to ratings from a pilot study ( N = 20 native
1 We discovered after norming was complete that two of Brysbaert et al. ' s (2014) items had been rendered incorrectly in our item set, due to file reading errors: infinity had been rendered as inf , and null had been rendered as nan . We opted to retain inf and nan in our norms because they are words in their own right (i.e., inf is a common coding term to represent the value of infinity, and nan is a shortened form of grandmother/granny), and because they had been rated by participants consistently enough to pass our data-checking and exclusion criteria.
Behav Res (2020) 52:1271 -1291
speakers of English from Lancaster University who did not take part in any other norming tasks) to have low variance in ratings across participants and to provide examples of the following criteria: low strength across all effectors ( shell ), medium strength across multiple effectors ( tourism ), high strength across multiple effectors ( driving , breathe ), and high strength in a single effector ( listen ).","s13428-019-01316-z.pdf~Method~13"
"s13428-019-01316-z.pdf","Method",14,"Method
In addition, five controls words were randomly interspersed throughout the item list in order to provide a means to evaluate participant performance as part of our data quality checks (see the Data Quality and Exclusions section). We selected control words using the same criteria as for calibrator words. For perceptual strength norming, the control words were grass , honey , laughing , noisy , and republic ; for action strength norming, the control words were bite , enduring , moving , stare , and vintage .
To populate the item lists, we used data binning to ensure each list contained items that varied both by their likelihood of being known to participants and by concreteness. We first performed a quartile split over all items according to the percentage of respondents in Brysbaert et al. ' s (2014) study who knew the word, giving four bins with percentage known in the intervals 85.0% -93.1%, 93.1% -100%, 100% -100%, and 100% -100%. Since over half the items were known by all participants (i.e., 100% known), the last two quartiles, and some of the second quartile, were undifferentiated by percentage known: we therefore used random sampling to allocate 100%knownitems to their relevant bins. We then performed a second quartile split on each of these four bins based on Brysbaert et al. ' s concreteness ratings, which meant that each percentage-known bin was further divided into four bins of most to least concrete, producing in 16 bins in total. Finally, in order to create each item list of 48 items, we drew a random sample of three items without replacement from each of the 16 bins.","s13428-019-01316-z.pdf~Method~14"
"s13428-019-01316-z.pdf","Method",15,"Method
Participants A total of 3,500 unique participants completed 32,456 surveys via Amazon ' s Mechanical Turk platform ( M = 7.12 item lists per participant). Participants could complete more than one word list, but could not complete the same list twice. Ratings for perceptual strength and action strength were gathered separately. That is, for a given list of words, a participant rated either all modalities of perceptual strength or all effectors of action strength but not both at the same time (although it was possible for individual participants to contribute to both perceptual and action strength norms on different occasions). The perceptual strength norms component of the study had 2,625 participants, with participants completing on average 5.99 lists each; the action strength norms component had 1,933 participants, with participants completing an average of 8.67 lists each. The participants were self-selected and had English as their first language. We recruited only experienced MTurk users who had already completed over
Behav Res (2020) 52:1271 -1291
1275
100 tasks (i.e., MTurk HITS > 100) with high-quality performance (i.e., > 97% HIT approval). We used TurkPrime (an interface to Mturk: Litman, Robinson, & Abberbock, 2016) to block duplicate IP addresses from completing the same item list, and to microbatch data collection into small groups of participants (which reduced overall costs and ensured the HITs were advertised over a longer time window). Participants were remunerated at US$2.75 per completed perceptual strength item list and US$2.25 per completed action strength item list (i.e., intended to reflect payment at US$9 per hour, pro rata, according to pilot timings of the task). Table 1 summarizes participant characteristics for age and sex. Ethics approval for the project was granted by Lancaster University Research Ethics Committee.","s13428-019-01316-z.pdf~Method~15"
"s13428-019-01316-z.pdf","Method",16,"Method
Data collection procedure Using Qualtrics survey software, we created a template survey that followed procedures developed for the original perceptual strength norms of Lynott and Connell (2009) and Lynott and Connell (2013). At the start of the survey, participants read an information sheet and indicated their informed consent to continue with the study. Participants then saw a detailed instructions screen that explained they would be asked to rate how much they experience everyday concepts using six perceptual senses/five action effectors from different parts of the body. The instructions further explained that there were no right or wrong answers and participants should use their own judgment; that the rating scales ran from 0 ( not experienced at all with that sense/ action ) to 5 ( experienced greatly with that sense/action ); and that if participants did not know the meaning of a word, they should check the ' Don ' t know the meaning of this word ' box
and move onto the next item. Participants also received a warning that because the study used words encountered in everyday life, this would occasionally mean that some words might be offensive or explicit, and participants were reminded of their right to withdraw. To aid participants in discriminating between the five different effectors during action strength norming, we presented images of a human avatar, to highlight the body part indicated by each effector (see Fig. 1).","s13428-019-01316-z.pdf~Method~16"
"s13428-019-01316-z.pdf","Method",17,"Method
Each item appeared individually on its own rating screen in a short piece of framing text followed by the relevant rating scales. For perceptual strength norming, the text read ' To what extent do you experience WORD, ' where WORD was replaced with the item in question in uppercase text. Underneath were six rating scales, one for each of the perceptual modalities under investigation, labeled ' By feeling through touch, ' ' By hearing, ' ' By sensations inside your body, ' ' By smelling, ' and ' By tasting ' ; the order of these modalities was randomized for each item list. For action strength norming, the text read ' To what extent do you experience WORD by performing an action with the, ' where WORD was replaced with the item in question in uppercase text. Underneath were five rating scales, one for each action effector, labeled ' Foot/leg, ' ' Hand/arm, ' ' Head excluding mouth, ' ' Mouth/throat, ' and ' Torso ' ; the order of these effectors was randomized for each item list. The label of each action effector was accompanied by a small version of the body avatar that was presented in the instructions. No default value was selected on any rating scale. At the bottom of the screen were a check box labeled ' Don ' t know the meaning of this word ' and a button labeled ' Next. ' Example images of the rating screens can be accessed on the OSF project page.
Table 1 Participant demographics for the separate components of data collection in the sensorimotor norms","s13428-019-01316-z.pdf~Method~17"
"s13428-019-01316-z.pdf","Method",18,"Method
Table 1 Participant demographics for the separate components of data collection in the sensorimotor norms
Perceptual strength, Sex = Female. Perceptual strength, N = 1,230. Perceptual strength, Age (Mean) = 36.9. Perceptual strength, Age ( SD ) = 11.0. , Sex = Male. , N = 1,371. , Age (Mean) = 33.3. , Age ( SD ) = 9.4. , Sex = Prefer not to say. , N = 4. , Age (Mean) = 37.0. , Age ( SD ) = 21.4. , Sex = Missing. , N = 20. , Age (Mean) = . , Age ( SD ) = . , Sex = All. , N = 2,625. , Age (Mean) = 35.0. , Age ( SD ) = 10.4. Action strength, Sex = Female. Action strength, N = 927. Action strength, Age (Mean) = 37.6. Action strength, Age ( SD ) = 10.7. , Sex = Male. , N = 1,000. , Age (Mean) = 34.0. , Age ( SD ) = 9.8. , Sex = Prefer not to say. , N = 4. , Age (Mean) = 35.0. , Age ( SD ) = 22.7. , Sex = Missing. , N = 2. , Age (Mean) = . , Age ( SD ) = . , Sex = All. , N = 1,933. , Age (Mean) = 35.7. , Age ( SD ) = 10.4. Sensorimotor combined, Sex = Female. Sensorimotor combined, N = 1,644. Sensorimotor combined, Age (Mean) = 36.8. Sensorimotor combined, Age ( SD ) = 10.8. , Sex = Male. , N = 1,823. , Age (Mean) = 33.2. , Age ( SD ) = 9.5. , Sex = Prefer not to say. , N = 12. , Age (Mean) = 30.2. , Age ( SD ) = 12.8. , Sex = Missing. , N = 21. , Age (Mean) = . , Age ( SD ) = . , Sex = All. , N = 3,500. , Age (Mean) =","s13428-019-01316-z.pdf~Method~18"
"s13428-019-01316-z.pdf","Method",19,"Method
Table 1 Participant demographics for the separate components of data collection in the sensorimotor norms
34.9. , Age ( SD ) = 10.3","s13428-019-01316-z.pdf~Method~19"
"s13428-019-01316-z.pdf","Method",20,"Method
Numbers are also provided for the overall combined dataset (in italics; providing the total number of unique participants), as some participants provided ratings for both the perceptual and action strength norms.
1276
Behav Res (2020) 52:1271 -1291
Fig. 1 Avatar images used to describe the area of each effector during action strength norming.
Participants could only move onto the next item if they had either (a) selected a rating on all scales or (b) checked the ' Don ' t know ' box. Participants were free to change their ratings until they clicked the ' Next ' button, but it was not possible to return to previous items once they had moved on.
Each list of 58 items started with the calibrator words, followed by the 48 test items and five control items in random order. The study was self-paced and was timed in piloting to be completed in approximately 18 min, for perceptual strength norming, and 15 min, for action strength norming.
Data checks and exclusions To ensure the data collected were of sufficiently high quality, we instituted a number of checks based on individual (participant) performance, item completion, and inter-rater agreement per list of words.","s13428-019-01316-z.pdf~Method~20"
"s13428-019-01316-z.pdf","Method",21,"Method
Every completed data file (i.e., the responses of a particular participant to a particular item list) was checked individually. Adata file was excluded as poor-quality data if the participant responded ' Don ' t know the meaning of this word ' to one or more of the control words (all of which were known by 100% of participants in the Brysbaert et al., 2014, concreteness norms), or if their ratings for the control words correlated at r < .2 with the existing norms for those words (see the Materials section); in all, 72 data files were excluded on this basis. Additionally, a small number of participants completed the same item list more than once due to incomplete screening criteria in early testing; when this happened, we retained only the first-submitted data file per participant and excluded the duplicates (27 in total). Words were considered as valid if they had at least ten ratings each for both perceptual and action ratings. In total 247 words were lost due to having low numbers of valid ratings. Note that we are making available the norms for these ' lowN ' words in a separate file from the main norms, as researchers may find them suitable for some purposes (e.g., where the focus is on sensory modalities and there are a sufficient number of ratings from the perceptual norms). We used imputation to resolve the issue of missing values for those items with a low number of responses. This was done for all lists, using multivariate imputation by
chained equations (MICE; van Buuren & GroothuisOudshoorn, 2011), and the final reported norms do not include any imputed values. From the remaining high-quality data files, we calculated Cronbach ' s (1951) alpha per item list per dimension: Responses were retained when the mean alpha across all dimensions was ≥ .8 and each individual dimension had alpha ≥ .7 (i.e., very good agreement overall).","s13428-019-01316-z.pdf~Method~21"
"s13428-019-01316-z.pdf","Method",22,"Method
Figure 2 summarizes data loss due to various exclusion criteria: Overall, a very low proportion of the data had to be excluded (0.6% of words, 0.8% of individual ratings). Our final item set thus comprised 39,707 lemmas, each of which had valid norming data in 11 sensorimotor dimensions. On average, the sensorimotor strength ratings for each item were based on 18.0 participants in the perceptual component (range N = [10, 74]), and 19.1 participants in the action component (range N = [10, 58]). These means exclude the control and calibrator words, which appeared in every item list and were therefore rated by almost all participants (means: perceptual N = 15,948.4, action N = 16,659.2).","s13428-019-01316-z.pdf~Method~22"
"s13428-019-01316-z.pdf","Results and discussion",23,"Results and discussion
We calculated summary statistics (mean rating and standard deviations) per dimension per word. Table 2 and Fig. 3 (violin plots) show the mean ratings per perceptual modality and action effectors, along with measures of spread. The interrater reliability was excellent for all dimensions: The mean Cronbach ' s alpha (calculated per item list and then averaged) for each perceptual modality (auditory .93, gustatory .96, haptic .92, interoceptive .92, olfactory .94, visual .90) was comparable to that from previous perceptual strength norms that had been collected in a traditional lab setting (Lynott & Connell, 2013), and the alpha values for action effectors were similar (foot .93, hand .91, head .85, mouth .92, and torso .89).
In Fig. 4, we provide some examples of how the sensorimotor profiles of particular concepts varied across dimensions. To quantify the distinctness of the information captured by each dimension, we ran principal component analysis (PCA) across all 11 dimensions and examined the uniqueness
Behav Res (2020) 52:1271 -1291
1277
Fig. 2 Schematic of data exclusions at each stage of the data preparation process
scores per dimension (i.e., the proportion of variance from each dimension that is unique and not shared with any extracted components). A parallel analysis (95th percentile) determined that the optimal number of components to extract was four, and the resulting uniqueness scores are given in Table 2. Overall, all 11 dimensions captured distinct information to
Table 2 Mean sensorimotor strength ratings (0 -5), standard deviations ( SD ), standard errors ( SE ), and uniqueness scores (proportions of unique variance, 0 -1) per sensorimotor dimension for the full sensorimotor norms of 39,707 words","s13428-019-01316-z.pdf~Results and discussion~23"
"s13428-019-01316-z.pdf","Results and discussion",24,"Results and discussion
Table 2 Mean sensorimotor strength ratings (0 -5), standard deviations ( SD ), standard errors ( SE ), and uniqueness scores (proportions of unique variance, 0 -1) per sensorimotor dimension for the full sensorimotor norms of 39,707 words
Perceptual Modality, M = . Perceptual Modality, SD = . Perceptual Modality, SE = . Perceptual Modality, Uniqueness = . Auditory, M = 1.51. Auditory, SD = 0.99. Auditory, SE = 0.005. Auditory, Uniqueness = .349. Gustatory, M = 0.32. Gustatory, SD = 0.70. Gustatory, SE = 0.003. Gustatory, Uniqueness = .122. Haptic, M = 1.07. Haptic, SD = 0.93. Haptic, SE = 0.005. Haptic, Uniqueness = .319. Interoceptive, M = 1.03. Interoceptive, SD = 0.88. Interoceptive, SE = 0.004. Interoceptive, Uniqueness = .342. Olfactory, M = 0.39. Olfactory, SD = 0.62. Olfactory, SE = 0.003. Olfactory, Uniqueness = .253. Visual, M = 2.90. Visual, SD = 0.90. Visual, SE = 0.005. Visual, Uniqueness = .267. Action Effector, M = . Action Effector, SD = . Action Effector, SE = . Action Effector, Uniqueness = . Foot/leg, M = 0.81. Foot/leg, SD = 0.75. Foot/leg, SE = 0.004. Foot/leg, Uniqueness = .282. Hand/arm, M = 1.45. Hand/arm, SD = 0.91. Hand/arm, SE = 0.005. Hand/arm, Uniqueness = .306. Head, M = 2.28. Head, SD = 0.72. Head, SE = 0.004. Head, Uniqueness = .431. Mouth/throat, M = 1.26. Mouth/throat, SD = 0.90. Mouth/throat, SE = 0.005. Mouth/throat, Uniqueness = .281. Torso, M","s13428-019-01316-z.pdf~Results and discussion~24"
"s13428-019-01316-z.pdf","Results and discussion",25,"Results and discussion
Table 2 Mean sensorimotor strength ratings (0 -5), standard deviations ( SD ), standard errors ( SE ), and uniqueness scores (proportions of unique variance, 0 -1) per sensorimotor dimension for the full sensorimotor norms of 39,707 words
= 0.82. Torso, SD = 0.67. Torso, SE = 0.003. Torso, Uniqueness = .187","s13428-019-01316-z.pdf~Results and discussion~25"
"s13428-019-01316-z.pdf","Results and discussion",26,"Results and discussion
varying extents: 12.2% of the information in gustatory strength was unique, whereas 43.0% of the information in head action strength was unique, with all other dimensions positioned in between.
Following Lynott and Connell (2009, 2013), we also calculated and included additional variables of interest for each word (numbers of participants who knew each item, modality and effector exclusivity, dominant dimension). In the following sections of results, we discuss these variables before examining the interrelationships between dimensions. The Appendix contains a full list of all variables included in the norms.
Number and percentage known We include in the norms a number of fields relating to how well-known each concept was in our sample of participants, calculated separately for the perceptual and action strength components. The number of participants who provided a valid rating for the concept rather than checking the ' don ' t know ' box (N_known.perceptual, N_known.action) and the number of valid participants who completed the item list featuring the concept (List_N.perceptual, List_N.action) formed the basis of calculating the proportion (0 -1) of participants who knew the concept (Percent_known.perceptual, Percent_known.action). We note that fewer participants knew the concepts in our sensorimotor strength norms ( M = 92.8% for perceptual component, M = 94.3% for action component) than did the participants in Brysbaert et al. ' s (2014) concreteness norms ( M = 96.5%).
1278
Behav Res (2020) 52:1271 -1291
Fig. 3 Violin plots showing the distribution of sensorimotor strength ratings per dimension and level of spread. Dots indicate the data points for individual items ( N = 39,707), solid red lines indicate mean ratings, and the shaded areas indicate ± 1 SD
Fig. 4 Polar plots for a range of individual concepts, showing the mean sensorimotor strength on each of the 11 dimensions. Similar plots can be automatically generated using the web application associated with the norms
Behav Res (2020) 52:1271 -1291
1279","s13428-019-01316-z.pdf~Results and discussion~26"
"s13428-019-01316-z.pdf","Results and discussion",27,"Results and discussion
Indeed, even though all concepts in our norms were known by at least 85% of Brysbaert et al. ' s concreteness participants, a sizeable number of concepts were known by less than 85% of our participants: some 7,205 items in the perceptual component and 4,940 items in the action component. For instance, the item languidly was known by only 46% (16 out of 35 participants) in perceptual strength norming and by 51% (18 out of 35 participants) in action strength norming, in contrast to 90% in Brysbaert et al. ' s concreteness norms. Since the participants in our sensorimotor norms and Brysbaert et al. ' s concreteness norms were drawn from the same pool (i.e., MTurk workers), it is unlikely that sampling differences alone could have produced the divergence in what is considered ' known. ' Although sample-based differences may have been at play, we speculate that the reason for this difference is that rating sensorimotor strength on individual modalities or effectors requires a more specific, detailed conceptual representation -that is, a deeper understanding of what the word means -than rating concreteness. Although 90% of participants felt they knew the word languidly well enough to rate it as a slightly abstract concept, only around half of respondents felt their understanding of languidly was up to rating the details of its sensorimotor experience. The more detailed the required semantic processing, the more conservative people appear to become in deciding that they ' know ' a word.","s13428-019-01316-z.pdf~Results and discussion~27"
"s13428-019-01316-z.pdf","Results and discussion",28,"Results and discussion
Exclusivity scores We calculated exclusivity scores per item (i.e., a measure of the extent to which a particular concept is experienced through a single dimension) as the rating range divided by the sum (Lynott & Connell, 2009). Exclusivity scores can be expressed as a proportion, and extend from 0 (completely multidimensional and experienced equally in all dimensions) to 1.0 (completely unidimensional and experienced solely through a single dimension). To allow for separate consideration of the perceptual and action components of the norms, we report in the norms separate exclusivity scores across the six perceptual modalities (i.e., Exclusivity.perceptual), the five action effectors (i.e., Exclusivity.action), and the 11 sensorimotor dimensions (i.e., Exclusivity.sensorimotor). Overall, the concepts were highly multidimensional, with a mean sensorimotor exclusivity score of 24.0% ( SD = 6.53%), and tended to involve a wider range of action effectors (effector exclusivity M = 34.4%, SD = 15.2%) than perceptual modalities (modality exclusivity M = 43.5%, SD = 13.0%) in their representations. The mean modality exclusivity of the present norms for 39,707 concepts is very similar to values from previous work, lying between those found for a sample of 400 nouns (39.2%: Lynott & Connell, 2013) and 423 adjectives (46.1%: Lynott & Connell, 2009), even though the present norms include an additional perceptual modality of interoception.
Byway of example, the most multidimensional word in the norms is everything , with sensorimotor exclusivity of 2.1%, which -perhaps unsurprisingly -is because everything is","s13428-019-01316-z.pdf~Results and discussion~28"
"s13428-019-01316-z.pdf","Results and discussion",29,"Results and discussion
experienced relatively strongly across all perceptual modalities and action effectors (rating range from 3.22 to 4.06). The most unidimensional word in the norms is monochromatically , with sensorimotor exclusivity of 62.9%, which resulted from the concept scoring strongly on visual strength (3.92) but weakly on everything else. However, it ' s important to note that high exclusivity does not necessarily mean high strength. If one considers modality exclusivity alone, rainbow is strongly visual (4.68), whereas unbudgeted is weakly visual (1.35), but they both score 100% on modality exclusivity (i.e., they are unimodally visual concepts) because all other modalities have perceptual strength of zero. Similarly, when it comes to effector exclusivity, blink strongly involves action with the head (4.75), whereas shorebird involves head action only weakly (0.71), but they both score 100% on effector exclusivity because all other effectors have action strength of zero. See Table 3 for the perceptual modality, action effector, and sensorimotor exclusivity scores per dominant dimension.
Dominant modalities and effectors We identified the dominant dimension of each concept in the norms according to which dimension has the highest rating (i.e., maximum sensorimotor strength), and labeled the dominant perceptual modality, dominant action effector, and the overall dominant sensorimotor dimension per item. When there was a tie for the highest rating (perceptual, N = 593; action, N = 706; sensorimotor, N = 478), we assigned a dominant dimension at random from the tied candidates. 2","s13428-019-01316-z.pdf~Results and discussion~29"
"s13428-019-01316-z.pdf","Results and discussion",30,"Results and discussion
Table 3 shows the numbers of concepts per dominant dimension as well as the mean ratings per dimension in each case; the means are shown separately according to whether the concept is classified by dominant perceptual modality, dominant action effector, or overall dominant sensorimotor dimension. For example, 4,528 words had auditory as the dominant perceptual modality, and based on just those words, the mean auditory rating was 3.04, whereas the mean gustatory rating for those words was 0.14. As had previously been found in small-scale perceptual strength norms (that focused either on highly perceptual concepts -Lynott & Connell, 2009; Winter, Perlman, & Majid, 2018 -or a representative random selections of concepts -Lynott & Connell, 2013), vision dominates the perceptual modalities. Here we show that vision is the overall dominant sensorimotor dimension: More concepts are dominated by vision than by the other ten dimensions put together. Some 57% of words in English are visually dominant, and -since our item set of approximately 40,000 words was chosen to represent a full adult vocabulary -this means that the majority of English word meanings are grounded in visual experience. Considering perceptual modalities alone, vision is the
2 We applied this method for consistency with the existing norms, but others may prefer to apply alternative methods of distinguishing between tied cases.
1280
Behav Res (2020) 52:1271 -1291
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)","s13428-019-01316-z.pdf~Results and discussion~30"
"s13428-019-01316-z.pdf","Results and discussion",31,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Perceptual Modality, N.N = Perceptual Modality. Perceptual Modality, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Perceptual Modality. Perceptual Modality, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Perceptual Modality. Perceptual Modality, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Perceptual Modality. Perceptual Modality, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = Perceptual Modality. Perceptual Modality, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Perceptual Modality. Perceptual Modality, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Perceptual Modality. Perceptual Modality, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = Perceptual Modality. Perceptual Modality, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = Perceptual Modality. Perceptual Modality, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Perceptual Modality. Perceptual Modality, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = Perceptual Modality. Perceptual Modality, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = Perceptual Modality. Perceptual Modality,","s13428-019-01316-z.pdf~Results and discussion~31"
"s13428-019-01316-z.pdf","Results and discussion",32,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Exclusivity.Exclusivity = Perceptual Modality. Auditory, N.N = 4,528. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 3.04. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.14. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.42. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 1.01. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.16. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.02. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.42. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 0.87. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.52. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 2.09. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.49. Auditory, Exclusivity.Exclusivity = 44.2%. Gustatory, N.N = 890. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.50. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. =","s13428-019-01316-z.pdf~Results and discussion~32"
"s13428-019-01316-z.pdf","Results and discussion",33,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
3.95. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.69. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 0.91. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.36. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.96. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.23. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.53. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.75. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 3.51. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.67. Gustatory, Exclusivity.Exclusivity = 29.5%. Haptic, N.N = 975. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.82. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.36. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 3.41. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 1.24. Haptic, Sensorimotor Dimension Auditory","s13428-019-01316-z.pdf~Results and discussion~33"
"s13428-019-01316-z.pdf","Results and discussion",34,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.36. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.68. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 1.21. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 2.76. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.80. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 0.98. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 1.25. Haptic, Exclusivity.Exclusivity = 37.4%. Interoceptive, N.N = 3,546. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.34. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.33. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.73. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 2.86. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.34. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.88. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic","s13428-019-01316-z.pdf~Results and discussion~34"
"s13428-019-01316-z.pdf","Results and discussion",35,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.85. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.11. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.67. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 1.54. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 1.20. Interoceptive, Exclusivity.Exclusivity = 36.8%. Olfactory, N.N = 216. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.65. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.98. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.87. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 0.84. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 3.58. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.02. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.42. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.10. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/","s13428-019-01316-z.pdf~Results and discussion~35"
"s13428-019-01316-z.pdf","Results and discussion",36,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Hand/ Head Mouth/. = 2.59. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 1.38. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.72. Olfactory, Exclusivity.Exclusivity = 40.7%. Visual, N.N = 29,552. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.36. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.24. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.12. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 0.81. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.35. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 3.16. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.87. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.53. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.22. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 1.04. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.81. Visual, Exclusivity.Exclusivity","s13428-019-01316-z.pdf~Results and discussion~36"
"s13428-019-01316-z.pdf","Results and discussion",37,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
= 44.8%. Action Effector, N.N = Action Effector. Action Effector, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Action Effector. Action Effector, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Action Effector. Action Effector, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Action Effector. Action Effector, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = Action Effector. Action Effector, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Action Effector. Action Effector, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Action Effector. Action Effector, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = Action Effector. Action Effector, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = Action Effector. Action Effector, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Action Effector. Action Effector, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = Action Effector. Action Effector, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = Action Effector. Action Effector, Exclusivity.Exclusivity = Action Effector. Foot/leg, N.N = 1,409. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.09. Foot/leg, Sensorimotor Dimension Auditory Gustatory","s13428-019-01316-z.pdf~Results and discussion~37"
"s13428-019-01316-z.pdf","Results and discussion",38,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.11. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.45. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 1.01. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.26. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 3.35. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 2.91. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.67. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.76. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 0.68. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 1.39. Foot/leg, Exclusivity.Exclusivity = 29.0%. Hand/arm, N.N = 6,917. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.10. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.22. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.09. Hand/arm, Sensorimotor Dimension","s13428-019-01316-z.pdf~Results and discussion~38"
"s13428-019-01316-z.pdf","Results and discussion",39,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 0.68. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.37. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 3.33. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.99. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 2.74. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.80. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 0.74. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.94. Hand/arm, Exclusivity.Exclusivity = 33.1%. Head, N.N = 26,714. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.60. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.22. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.78. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 1.09. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.33. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero-","s13428-019-01316-z.pdf~Results and discussion~39"
"s13428-019-01316-z.pdf","Results and discussion",40,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.81. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.70. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.14. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.49. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 1.18. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.71. Head, Exclusivity.Exclusivity = 34.5%. Mouth/throat, N.N = 3,707. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.04. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.36. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.97. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 1.08. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.88. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.53. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.39. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head","s13428-019-01316-z.pdf~Results and discussion~40"
"s13428-019-01316-z.pdf","Results and discussion",41,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Mouth/.Arm = 1.15. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.00. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 3.10. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.67. Mouth/throat, Exclusivity.Exclusivity = 38.9%. Torso, N.N = 961. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.78. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.24. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.80. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 1.73. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.45. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.93. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 1.14. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.50. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.60. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 0.79. Torso, Sensorimotor Dimension Auditory Gustatory Haptic","s13428-019-01316-z.pdf~Results and discussion~41"
"s13428-019-01316-z.pdf","Results and discussion",42,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 2.75. Torso, Exclusivity.Exclusivity = 31.3%. Sensorimotor Dimension, N.N = Sensorimotor Dimension. Sensorimotor Dimension, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Sensorimotor Dimension. Sensorimotor Dimension, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Sensorimotor Dimension. Sensorimotor Dimension, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Sensorimotor Dimension. Sensorimotor Dimension, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = Sensorimotor Dimension. Sensorimotor Dimension, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Sensorimotor Dimension. Sensorimotor Dimension, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Sensorimotor Dimension. Sensorimotor Dimension, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = Sensorimotor Dimension. Sensorimotor Dimension, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = Sensorimotor Dimension. Sensorimotor Dimension, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = Sensorimotor Dimension. Sensorimotor Dimension, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = Sensorimotor Dimension. Sensorimotor Dimension, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = Sensorimotor Dimension. Sensorimotor Dimension, Exclusivity.Exclusivity = Sensorimotor Dimension.","s13428-019-01316-z.pdf~Results and discussion~42"
"s13428-019-01316-z.pdf","Results and discussion",43,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Auditory, N.N = 2,690. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 3.43. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.13. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.45. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 0.93. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.15. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.15. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.40. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 0.89. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.37. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 2.08. Auditory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.47. Auditory, Exclusivity.Exclusivity = 25.5%. Gustatory, N.N = 661. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.47. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 4.11. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero-","s13428-019-01316-z.pdf~Results and discussion~43"
"s13428-019-01316-z.pdf","Results and discussion",44,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.78. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 0.83. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.51. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 3.09. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.23. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.51. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.70. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 3.37. Gustatory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.62. Gustatory, Exclusivity.Exclusivity = 19.9%. Haptic, N.N = 649. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.80. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.40. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 3.57. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 1.25. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. =","s13428-019-01316-z.pdf~Results and discussion~44"
"s13428-019-01316-z.pdf","Results and discussion",45,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
0.40. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.75. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 1.22. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 2.56. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.83. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 0.97. Haptic, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 1.28. Haptic, Exclusivity.Exclusivity = 20.7%. Interoceptive, N.N = 1,766. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.37. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.35. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.86. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 3.26. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.37. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.02. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg =","s13428-019-01316-z.pdf~Results and discussion~45"
"s13428-019-01316-z.pdf","Results and discussion",46,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
0.94. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.18. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.45. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 1.50. Interoceptive, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 1.35. Interoceptive, Exclusivity.Exclusivity = 20.4%. Olfactory, N.N = 176. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.59. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.03. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.86. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 0.81. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 3.78. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.12. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.42. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.07. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.49. Olfactory,","s13428-019-01316-z.pdf~Results and discussion~46"
"s13428-019-01316-z.pdf","Results and discussion",47,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 1.31. Olfactory, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.74. Olfactory, Exclusivity.Exclusivity = 25.1%. Visual, N.N = 22,774. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.36. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.24. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.20. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 0.74. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.38. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 3.36. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.84. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.52. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.11. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 0.95. Visual, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.79. Visual, Exclusivity.Exclusivity = 25.1%. Foot/leg, N.N =","s13428-019-01316-z.pdf~Results and discussion~47"
"s13428-019-01316-z.pdf","Results and discussion",48,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
428. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.05. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.11. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.49. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 1.21. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.18. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 3.01. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 3.66. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.75. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.77. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 0.69. Foot/leg, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 1.57. Foot/leg, Exclusivity.Exclusivity = 22.5%. Hand/arm, N.N = 1,434. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.04. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head","s13428-019-01316-z.pdf~Results and discussion~48"
"s13428-019-01316-z.pdf","Results and discussion",49,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Mouth/. = 0.17. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.08. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 0.88. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.26. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.83. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 1.17. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 3.46. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.90. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 0.79. Hand/arm, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 1.14. Hand/arm, Exclusivity.Exclusivity = 22.1%. Head, N.N = 7,740. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.57. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.21. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.52. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive =","s13428-019-01316-z.pdf~Results and discussion~49"
"s13428-019-01316-z.pdf","Results and discussion",50,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
1.37. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.25. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.13. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.66. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.05. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.90. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 1.45. Head, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.72. Head, Exclusivity.Exclusivity = 22.5%. Mouth/throat, N.N = 1,166. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.87. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.17. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.88. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 1.30. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.70. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.23. Mouth/throat, Sensorimotor Dimension Auditory","s13428-019-01316-z.pdf~Results and discussion~50"
"s13428-019-01316-z.pdf","Results and discussion",51,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 0.41. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.18. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.14. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 3.51. Mouth/throat, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 0.78. Mouth/throat, Exclusivity.Exclusivity = 21.5%. Torso, N.N = 223. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.74. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.23. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 1.48. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.ceptive = 1.88. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 0.36. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/. = 2.24. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Leg = 1.04. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Arm = 1.38. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.","s13428-019-01316-z.pdf~Results and discussion~51"
"s13428-019-01316-z.pdf","Results and discussion",52,"Results and discussion
Table 3 Numbers of concepts per dominant perceptual modality, dominant action effector, and overall dominant sensorimotor dimension, with mean ratings of sensorimotor strength (0 -5) and exclusivity scores (modality, effector, or sensorimotor)
= 1.57. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Throat = 0.87. Torso, Sensorimotor Dimension Auditory Gustatory Haptic Intero- Olfactory Visual Foot/ Hand/ Head Mouth/.Torso = 3.17. Torso, Exclusivity.Exclusivity = 21.7%","s13428-019-01316-z.pdf~Results and discussion~52"
"s13428-019-01316-z.pdf","Results and discussion",53,"Results and discussion
The mean rating for each dominant dimension is in bold.
most important modality (74% of items are visually dominant; e.g., cloud , mirror ), followed by auditory (11%; thunder , mockery ), interoceptive (9%; ulcer , empathy ), haptic (2%; prickly , blister ), gustatory (2%; pizza , sweet ), and olfactory (< 1%; perfume , skunk ). When considering action effectors alone, the most important effector is the head excluding mouth and throat; 67% of items are dominated by head action; e.g., stare , daydream ), followed by the hand and arm (17%; throw , fork ), mouth and throat (9%; eat , pronounce ), foot and leg (4%; kick , sandal ), and torso (2%; slouch , polo shirt ).
Relationship between dimensions The correlations between individual perceptual modalities and action effectors are shown in Fig. 5, a correlation matrix plot between all 11 dimensions for the mean ratings of sensorimotor strength ( N = 39,707). Given the exploratory nature of the analysis (i.e., without hypotheses to confirm), we opted not to include inferential statistics such as p values, and report","s13428-019-01316-z.pdf~Results and discussion~53"
"s13428-019-01316-z.pdf","Results and discussion",54,"Results and discussion
only the correlation coefficient. As we had previously found for perceptual strength norms (Lynott & Connell, 2009, 2013; see also Connell, Lynott, & Banks, 2018), gustatory and olfactory strength were highly correlated (e.g., foodstuffs like peach are experienced via taste and smell), as were visual and haptic strength (e.g., most objects and textures that can be touched are also visible, such as bowl or prickly ), whereas auditory strength was negatively related to all other modalities except interoception (e.g., an auditory experience such as rhythm or beep is often difficult to touch, taste, smell, or see). Interoception was also negatively correlated with vision, reflecting the fact that sensations inside the body (e.g., nausea , heartbreak ) are typically not visible. Nonetheless, despite their intercorrelations, all modalities were distinct for at least some concepts. For example, some olfactory experience does not relate to food, and hence has no gustatory counterpart (e.g., perfume ), and
Behav Res (2020) 52:1271 -1291
1281
Fig. 5 Correlation matrix plot between the 11 dimensions for mean ratings of sensorimotor strength ( N = 39,707). Larger circles indicate stronger correlations, with red shades being positive and blue shades being negative
some taste concepts involve no smell (e.g., salty ). Similarly, some haptic experience is not easily visible (e.g., heat , clammy ), and many visually strong concepts cannot be touched (e.g., cloud , yellow ).","s13428-019-01316-z.pdf~Results and discussion~54"
"s13428-019-01316-z.pdf","Results and discussion",55,"Results and discussion
Turning to the relationships between action effectors, we found that the strengths of foot and torso action were highly correlated. One likely explanation for the correlation between the foot and torso action ratings is that in the real world, many actions of the foot/leg also involve the torso, such as sitting and climbing , as do experiences of objects such as bed , bath , and clothing . To a slightly lesser extent, but for much the same reasons, hand action strength was also correlated with foot and torso action strength (e.g., climbing and bath also involve experience of hand action). Head and mouth action strength were also moderately correlated, plausibly because acts of social communication involve action with both the mouth/throat for vocalization and the rest of the head for attending and facial expression, such as debate , storytelling , and laughing . Nonetheless, mouth and head actions were separable: Food and eating concepts tend to involve strong mouth action but weak head action (e.g., bagel , chew ). Moreover, experiences that involve strong head action but weak mouth action include those relating to hearing (e.g., listening , noisy , smoke alarm ) and interoception (e.g., earache , dizzy , delirium ).
Indeed, action effectors add a number of new insights to the relationship between perception and action in the representation of concepts. As we suggested above, the role of head","s13428-019-01316-z.pdf~Results and discussion~55"
"s13428-019-01316-z.pdf","Results and discussion",56,"Results and discussion
action strength in hearing and interoceptive experiences underlies its correlation with auditory and interoceptive strength. Haptic perceptual strength is strongly correlated with experience of hand action (perhaps unsurprisingly), but also to some extent with foot and torso action: that is, people mainly feel through touch by using their hands, but also by using other major body parts. Visual strength also correlates with hand action, consistent with the visual-haptic relationship that most touchable things can be seen. Mouth action strength correlated negatively with visual and haptic strength (e.g., most things that are seen and touched are not placed in the mouth, such as dog and prickly ), but positively with all other modalities. Mouth action and auditory strength were correlated mostly due to experience of vocalizations (e.g., sing , poetry , roar ), and experiences of food and eating (e.g., chocolate , sip ) accounted for the relationship between mouth action and gustatory/olfactory strength. Finally, mouth action also correlated with interoceptive strength, primarily for concepts that were identified by Connell, Lynott, and Banks (2018) as domains of interoceptive experience, such as (mal)function of the respiratory and digestive systems (e.g., vomiting , breathe , sneezing ) and narcotics (e.g., amphetamine , tequila ). Similarly, torso action correlates with interoceptive strength for concepts relating to digestion (e.g., gastrointestinal , hungry ) and (ill) health (e.g., flu , heart attack , achiness ).
The relationships between individual perceptual modalities and action effectors are also illustrated in the
1282
continuity between concepts that are rated highly in the same dimensions (see Fig. 6, which contains separate t -SNE plots for the perceptual and action components, labeled by dominant modality/effector 3 ). As we noted earlier, vision dominates the perceptual modalities, and head action dominates the effectors, but other dimensions are nonetheless distinct.","s13428-019-01316-z.pdf~Results and discussion~56"
"s13428-019-01316-z.pdf","Study 2a: Identifying the optimal composite variable of sensorimotor experience",57,"Study 2a: Identifying the optimal composite variable of sensorimotor experience
Our goals in this validation study were twofold: we wished to empirically determine the best composite strength variable (i.e., single value) for representing a concept ' s multidimensional sensorimotor profile, and to demonstrate the utility of sensorimotor strength as a semantic predictor in word processing. Although an 11-dimension sensorimotor profile is a rich source of semantic information about a particular concept, it can nonetheless be somewhat unwieldy for some uses. It is often valuable to aggregate multiple dimensions into a single composite variable, such as for use as a predictor in regression analyses without unnecessarily inflating the number of parameters, or for fair comparison with other single-variable semantic measures. There are many different potential methods of creating such a composite variable. Previous work on perceptual strength had used the strength of the dominant modality (i.e., the maximum perceptual strength rating across all modalities) as the preferred composite variable (e.g., Connell & Lynott, 2016a; Connell et al., 2018; Winter et al., 2018), finding that it offered a better fit to visual word recognition performance than did alternative measures (Connell & Lynott, 2012a). However, work in Serbian (Filipovi ć Đ ur đ evi ć et al., 2016) showed that the best fit emerged from summed perceptual strength (i.e., sum of perceptual strength ratings across all modalities) or vector length (i.e., Euclidean distance of the multidimensional vector of perceptual strength ratings from the origin). It is difficult to be certain whether this variability is due to language differences (i.e., English vs. Serbian) or to sampling differences (i.e., hundreds of words with limited overlap). We therefore sought to determine the best single composite variable for our 11-dimension sensorimotor norms by using a much larger and more representative sample of concepts in English (i.e., tens of thousands of words). As in previous studies (e.g., Connell & Lynott, 2012a), we judged the ' best ' variable to be the one that offers the best fit to","s13428-019-01316-z.pdf~Study 2a: Identifying the optimal composite variable of sensorimotor experience~57"
"s13428-019-01316-z.pdf","Study 2a: Identifying the optimal composite variable of sensorimotor experience",58,"Study 2a: Identifying the optimal composite variable of sensorimotor experience
3 The t -distributed stochastic neighbor embedding ( t -SNE; Maaten & Hinton, 2008) approach is a nonlinear, probabilistic technique for dimensionality reduction that is well-suited to visualizing patterns in multidimensional data. In particular, the approach has been found to be good at preserving local structure from high-dimensional data sets in two-dimensional representations while also conveying global structure, and thus produces a visual display that best preserves the interdimensional relationships between items.
Behav Res (2020) 52:1271 -1291
Fig. 6 The t -distributed stochastic neighbor embedding ( t -SNE) plots of the perceptual strength norms (panel A, labeled by the dominant modality) and the action strength norms (panel B, labeled by the dominant effector). The plots provide two-dimensional visualizations of the continuity between concepts that are rated highly in the same dimensions
lexical decision latency, a task in which semantic facilitation emerges from automatic and implicit access to the sensorimotor basis of the concept (i.e., the sensorimotor simulation of word meaning). To ensure the generalizability of the best composite variable and demonstrate its utility as a semantic predictor in visual word recognition, we examined lexical decision performance across two different datasets (i.e., English
Behav Res (2020) 52:1271 -1291
1283
Lexicon Project, British Lexicon Project) and using two performance measures (response time and accuracy).","s13428-019-01316-z.pdf~Study 2a: Identifying the optimal composite variable of sensorimotor experience~58"
"s13428-019-01316-z.pdf","Method",59,"Method
Materials We collated a set of 22,297 words that represented the intersection of data between our sensorimotor strength norms and lexical decision data from the English Lexicon Project (ELP; Balota, et al., 2007), and a separate set of 11,768 words that represented the intersection with the British Lexicon Project (BLP; Keuleers, Lacey, Rastle, & Brysbaert, 2012). For each ELP and BLP dataset, we extracted the dependent variables of zRT (i.e., lexical decision RT standardized per participant) and accuracy, as well as a set of lexical predictors that typically predict lexical decision performance (log SUBTLEXus word frequency, length in letters, number of syllables, and orthographic Levenshtein distance to the 20 nearest neighbors).
Candidate composite variables There are a number of ways to reduce an 11-dimension profile of sensorimotor strength to a single composite variable, and we examined the six most promising candidates. Most of the candidate variables we tested are distance metrics in vector space of a particular concept (i.e., an 11-dimension vector) from the origin. Minkowski distance (with exponent parameter m ) is a generalization of these distance metrics: roughly speaking, the highest-value dimension always contributes to the calculated distance, and m determines the extent to which the other dimensions contribute according to how close their values are to the highestvalue dimension (see, e.g., Han, Kamber, & Pei, 2011, p. 72). That is, low-value m means that all dimensions make noticeable contributions to the calculated distance, whereas highvalue m means only the highest-value dimension(s) make noticeable contributions to the calculated distance.
Our set of candidate variables is as follows:
Maximum strength : the highest rating across the 11 sensorimotor dimensions for a concept. Theoretically, maximum strength represents sensorimotor strength of the dominant dimension, which has previously been found to be the best composite variable of perceptual strength (Connell & Lynott, 2012a, 2016a; Connell et al., 2018). Maximum strength is consistent with Chebyshev distance of the vector from the origin (Minkowski distance m = ∞ ), where the distance between two vectors is equal to the greatest of their differences along any coordinate dimension (Abello, Pardalos, & Resende, 2013).","s13428-019-01316-z.pdf~Method~59"
"s13428-019-01316-z.pdf","Method",60,"Method
Minkowski 10 distance : Minkowski distance at m = 10 of the vector from the origin. Theoretically, it represents the sensorimotor strength of the dominant dimension, plus an attenuated influence of any other dimensions that are nearly as strong as the dominant dimension.
Minkowski 3 distance : Minkowski distance at m = 3 of the vector from the origin. Theoretically, it represents the sensorimotor strength in all dimensions, but the influence of weaker dimensions is attenuated, and it has been proposed as the optimal value for modeling multisensory cue integration in perception (To, Baddeley, Troscianko, & Tolhurst, 2011). As compared to Minkowski 10, the Minkowski 3 distance receives a greater contribution from weaker dimensions.
Euclidean vector length : the straight-line distance of the vector from the origin (Minkowski distance m = 2). Theoretically, it represents the sensorimotor strength in all dimensions without attenuation, but the highest-value dimensions are most important, because they are farthest from the origin.
Summed strength : the sum of all ratings across the 11 sensorimotor dimensions for a concept, consistent with the Manhattan (i.e., city block) distance of the vector from the origin (Minkowski distance m = 1), which is statistically equivalent to mean strength as a predictor in regression analyses. Theoretically, it represents all dimensions with equal importance.
PCA component : the dimensionality reduction of all 11 dimensions via PCA to a single component (saved via regression method), with the computed factor standardized to a mean of zero. Theoretically, the PCA method preserves the common variance of all 11 dimensions (24.8% of overall original variance; 34.4% of the variance of the perceptual strength norms; 34.4%, and 40.6% of the variance of the action strength norms) in a single variable.","s13428-019-01316-z.pdf~Method~60"
"s13428-019-01316-z.pdf","Method",61,"Method
Design and analysis We performed Bayesian linear regressions on four dependent variables -zRT and accuracy from both ELP and BLP -using JSZ default priors ( r scale = .354) and Bayesian adaptive sampling (JASP Team, 2019). To reproduce this analysis, JASP analysis files are deposited in the OSF repository. In each analysis, we built a null model of lexical predictors (log SUBTLEX word frequency, number of letters, number of syllables, orthographic Levenshtein distance), and then added a single candidate composite variable to form the alternative model and used Bayes factors (BF 10 ) to quantify the evidence in favor of the alternative model over the null. Finally, we compared BFs across models to select the best-performing composite variable for each dependent variable. Due to the magnitude of the BF values, we report natural log BFs throughout.","s13428-019-01316-z.pdf~Method~61"
"s13428-019-01316-z.pdf","Results and discussion",62,"Results and discussion
Overall, we found that all composite variables of the sensorimotor norms reliably predicted lexical decision performance above and beyond the null model of lexical predictors, for both response times and accuracy, in both the ELP and BLP datasets. In Table 4, we report the log BF per candidate
1284
Behav Res (2020) 52:1271 -1291
Table 4 Bayesian linear regression results for English Lexicon Project (ELP) and British Lexicon Project (BLP) lexical decision response times (RTs) and accuracy, showing log Bayes factors (logBF10) for each candidate composite variable of sensorimotor strength against the null model","s13428-019-01316-z.pdf~Results and discussion~62"
"s13428-019-01316-z.pdf","Results and discussion",63,"Results and discussion
Table 4 Bayesian linear regression results for English Lexicon Project (ELP) and British Lexicon Project (BLP) lexical decision response times (RTs) and accuracy, showing log Bayes factors (logBF10) for each candidate composite variable of sensorimotor strength against the null model
RT, Model. = Null ( lexical variables). RT, English Lexicon Project ( N = 22,297).logBF10 = . RT, English Lexicon Project ( N = 22,297).R 2 = .591. RT, English Lexicon Project ( N = 22,297).∆ R 2 = . RT, British Lexicon Project ( N = 11,768).logBF10 = . RT, British Lexicon Project ( N = 11,768).R 2 = .485. RT, British Lexicon Project ( N = 11,768).∆ R 2 = . RT, Model. = Max strength. RT, English Lexicon Project ( N = 22,297).logBF10 = 165.420. RT, English Lexicon Project ( N = 22,297).R 2 = .597. RT, English Lexicon Project ( N = 22,297).∆ R 2 = .006. RT, British Lexicon Project ( N = 11,768).logBF10 = 175.912. RT, British Lexicon Project ( N = 11,768).R 2 = .501. RT, British Lexicon Project ( N = 11,768).∆ R 2 = .016. RT, Model. = Minkowski 10. RT, English Lexicon Project ( N = 22,297).logBF10 = 177.86. RT, English Lexicon Project ( N = 22,297).R 2 = .598. RT, English Lexicon Project ( N = 22,297).∆ R 2 = .007. RT, British Lexicon Project ( N = 11,768).logBF10 = 193.544. RT, British Lexicon Project ( N = 11,768).R 2 = .502. RT, British Lexicon Project ( N = 11,768).∆ R 2 = .017. RT, Model. = Minkowski 3. RT, English Lexicon Project ( N = 22,297).logBF10 =","s13428-019-01316-z.pdf~Results and discussion~63"
"s13428-019-01316-z.pdf","Results and discussion",64,"Results and discussion
Table 4 Bayesian linear regression results for English Lexicon Project (ELP) and British Lexicon Project (BLP) lexical decision response times (RTs) and accuracy, showing log Bayes factors (logBF10) for each candidate composite variable of sensorimotor strength against the null model
202.551. RT, English Lexicon Project ( N = 22,297).R 2 = .598. RT, English Lexicon Project ( N = 22,297).∆ R 2 = .007. RT, British Lexicon Project ( N = 11,768).logBF10 = 228.285. RT, British Lexicon Project ( N = 11,768).R 2 = .505. RT, British Lexicon Project ( N = 11,768).∆ R 2 = .020. RT, Model. = Euclidean. RT, English Lexicon Project ( N = 22,297).logBF10 = 192.129. RT, English Lexicon Project ( N = 22,297).R 2 = .598. RT, English Lexicon Project ( N = 22,297).∆ R 2 = .007. RT, British Lexicon Project ( N = 11,768).logBF10 = 210.165. RT, British Lexicon Project ( N = 11,768).R 2 = .503. RT, British Lexicon Project ( N = 11,768).∆ R 2 = .018. RT, Model. = Summed strength. RT, English Lexicon Project ( N = 22,297).logBF10 = 142.813. RT, English Lexicon Project ( N = 22,297).R 2 = .596. RT, English Lexicon Project ( N = 22,297).∆ R 2 = .005. RT, British Lexicon Project ( N = 11,768).logBF10 = 136.651. RT, British Lexicon Project ( N = 11,768).R 2 = .497. RT, British Lexicon Project ( N = 11,768).∆ R 2 = .012. RT, Model. = PCA. RT, English Lexicon Project ( N = 22,297).logBF10 = 54.532. RT, English Lexicon Project ( N = 22,297).R 2 =","s13428-019-01316-z.pdf~Results and discussion~64"
"s13428-019-01316-z.pdf","Results and discussion",65,"Results and discussion
Table 4 Bayesian linear regression results for English Lexicon Project (ELP) and British Lexicon Project (BLP) lexical decision response times (RTs) and accuracy, showing log Bayes factors (logBF10) for each candidate composite variable of sensorimotor strength against the null model
.593. RT, English Lexicon Project ( N = 22,297).∆ R 2 = .002. RT, British Lexicon Project ( N = 11,768).logBF10 = 50.747. RT, British Lexicon Project ( N = 11,768).R 2 = .490. RT, British Lexicon Project ( N = 11,768).∆ R 2 = .005. Accuracy, Model. = Null ( lexical variables). Accuracy, English Lexicon Project ( N = 22,297).logBF10 = . Accuracy, English Lexicon Project ( N = 22,297).R 2 = .237. Accuracy, English Lexicon Project ( N = 22,297).∆ R 2 = . Accuracy, British Lexicon Project ( N = 11,768).logBF10 = . Accuracy, British Lexicon Project ( N = 11,768).R 2 = .286. Accuracy, British Lexicon Project ( N = 11,768).∆ R 2 = . Accuracy, Model. = Max strength. Accuracy, English Lexicon Project ( N = 22,297).logBF10 = 88.240. Accuracy, English Lexicon Project ( N = 22,297).R 2 = .244. Accuracy, English Lexicon Project ( N = 22,297).∆ R 2 = .007. Accuracy, British Lexicon Project ( N = 11,768).logBF10 = 105.252. Accuracy, British Lexicon Project ( N = 11,768).R 2 = .299. Accuracy, British Lexicon Project ( N = 11,768).∆ R 2 = .013. Accuracy, Model. = Minkowski 10. Accuracy, English Lexicon Project ( N = 22,297).logBF10 = 93.828. Accuracy, English Lexicon Project ( N = 22,297).R 2 = .244. Accuracy, English Lexicon Project ( N = 22,297).∆ R 2 = .007. Accuracy, British Lexicon Project ( N =","s13428-019-01316-z.pdf~Results and discussion~65"
"s13428-019-01316-z.pdf","Results and discussion",66,"Results and discussion
Table 4 Bayesian linear regression results for English Lexicon Project (ELP) and British Lexicon Project (BLP) lexical decision response times (RTs) and accuracy, showing log Bayes factors (logBF10) for each candidate composite variable of sensorimotor strength against the null model
11,768).logBF10 = 114.398. Accuracy, British Lexicon Project ( N = 11,768).R 2 = .300. Accuracy, British Lexicon Project ( N = 11,768).∆ R 2 = .014. Accuracy, Model. = Minkowski 3. Accuracy, English Lexicon Project ( N = 22,297).logBF10 = 102.067. Accuracy, English Lexicon Project ( N = 22,297).R 2 = .245. Accuracy, English Lexicon Project ( N = 22,297).∆ R 2 = .008. Accuracy, British Lexicon Project ( N = 11,768).logBF10 = 138.688. Accuracy, British Lexicon Project ( N = 11,768).R 2 = .303. Accuracy, British Lexicon Project ( N = 11,768).∆ R 2 = .017. Accuracy, Model. = Euclidean. Accuracy, English Lexicon Project ( N = 22,297).logBF10 = 93.375. Accuracy, English Lexicon Project ( N = 22,297).R 2 = .244. Accuracy, English Lexicon Project ( N = 22,297).∆ R 2 = .007. Accuracy, British Lexicon Project ( N = 11,768).logBF10 = 131.714. Accuracy, British Lexicon Project ( N = 11,768).R 2 = .302. Accuracy, British Lexicon Project ( N = 11,768).∆ R 2 = .016. Accuracy, Model. = Summed strength. Accuracy, English Lexicon Project ( N = 22,297).logBF10 = 69.975. Accuracy, English Lexicon Project ( N = 22,297).R 2 = .242. Accuracy, English Lexicon Project ( N = 22,297).∆ R 2 = .005. Accuracy, British Lexicon Project ( N = 11,768).logBF10 = 92.785. Accuracy, British Lexicon Project ( N =","s13428-019-01316-z.pdf~Results and discussion~66"
"s13428-019-01316-z.pdf","Results and discussion",67,"Results and discussion
Table 4 Bayesian linear regression results for English Lexicon Project (ELP) and British Lexicon Project (BLP) lexical decision response times (RTs) and accuracy, showing log Bayes factors (logBF10) for each candidate composite variable of sensorimotor strength against the null model
11,768).R 2 = .298. Accuracy, British Lexicon Project ( N = 11,768).∆ R 2 = .012. Accuracy, Model. = PCA. Accuracy, English Lexicon Project ( N = 22,297).logBF10 = 43.377. Accuracy, English Lexicon Project ( N = 22,297).R 2 = .241. Accuracy, English Lexicon Project ( N = 22,297).∆ R 2 = .004. Accuracy, British Lexicon Project ( N = 11,768).logBF10 = 29.613. Accuracy, British Lexicon Project ( N = 11,768).R 2 = .290. Accuracy, British Lexicon Project ( N = 11,768).∆ R 2 = .004","s13428-019-01316-z.pdf~Results and discussion~67"
"s13428-019-01316-z.pdf","Results and discussion",68,"Results and discussion
composite variable, as well as proportion of variance explained by each variable (i.e., R 2 change from the null model). The best-performing composite variable of sensorimotor strength was Minkowski 3 strength, which consistently outperformed the other candidates across all four dependent measures (i.e., RT and accuracy in both ELP and BLP). Although several candidate variables explained similar amounts of variance in lexical decision performance (e.g., Minkowski 10, Minkowski 3, and Euclidean distance all explain 0.7% of the variation in ELP RTs), BFs clearly differentiated between their strength of evidence. Model comparisons showed that the data were between a thousand and several million times more likely under a model with Minkowski 3 strength than under the next-best candidate variable. 4
Minkowski 3 strength therefore represents an optimal means of aggregating 11 dimensions of sensorimotor strength into a single composite variable. It acted as a powerful semantic facilitator in lexical decision performance, explaining 0.7% -0.8% of variance in the ELP dataset, and 1.7% -2.0% of variance in the BLP dataset (above the null model of lexical predictors), which compares favorably with other semantic facilitation effects in the literature (e.g., Connell & Lynott, 2012a, 2016a; Kuperman et al., 2014). The previous best composite variable for perceptual strength, maximum strength in the dominant dimension, also performed very well, demonstrating that the dominant perceptual modality or action
4 For ELP RTs, the evidence for Minkowski 3 strength was log BF = 10.42 times better than that for the next-best variable, Euclidean distance; for BLP RTs, Minkowski 3 was log BF = 18.12 times better than Euclidean distance; for ELP accuracy, Minkowski 3 was log BF = 8.24 times better than Minkowski 10; and for BLP accuracy, Minkowski 3 was log BF = 6.97 times better than Euclidean distance.","s13428-019-01316-z.pdf~Results and discussion~68"
"s13428-019-01316-z.pdf","Results and discussion",69,"Results and discussion
effector is indeed highly important for semantic facilitation in visual word recognition. Nonetheless, the superior performance of Minkowski 3 strength indicates that other sensorimotor dimensions that are strongly involved in a concept ' s experience -even if they are not dominant -are also important for semantic facilitation. We return to the importance of the Minkowski 3 measure in the General Discussion.","s13428-019-01316-z.pdf~Results and discussion~69"
"s13428-019-01316-z.pdf","Study 2b: Validating the independent utility of perceptual and action strength",70,"Study 2b: Validating the independent utility of perceptual and action strength
Identifying the optimal composite variable of Minkowski 3 strength leads us to our second goal: We wished to replicate the utility of perceptual strength ratings in modeling people ' s performance in cognitive tasks, and establish the independent utility of action strength as a performance predictor. Although perceptual strength has enjoyed a number of empirical demonstrations of its effect on behavior, in tasks such as word recognition and modality detection (e.g., Connell & Lynott, 2010, 2012a, 2016a; Connell et al., 2018), the same is not true of action strength. Previous work has shown that other actionrelated variables can predict word recognition performance (Siakaluk, Pexman, Aguilera, Owen, & Sears, 2008) and semantic judgments (Pexman, Muraki, Sidhu, Siakaluk & Yap, 2019), although no study to date has examined the effect of action experience using the range of effectors and the scale of the present sensorimotor norms. It is therefore important to evaluate our particular measures of action strength in their own right. Specifically, it is important to establish how the effects of our chosen composite sensorimotor strength
Behav Res (2020) 52:1271 -1291
1285
variable may be due to both perceptual and action dimensions. In our final validation exercise, we therefore calculated our optimal composite variable separately for perceptual and action strength (i.e., Minkowski 3 distance calculated separately for six dimensions of perceptual strength and five dimensions of action strength) and examined their relative contributions in predicting lexical decision performance.","s13428-019-01316-z.pdf~Study 2b: Validating the independent utility of perceptual and action strength~70"
"s13428-019-01316-z.pdf","Method",71,"Method
We utilized the same datasets as in Study 2a, and the method was the same as in Study 2a, with the following exceptions.
Composite variables Rather than calculate our composite variables across all 11 dimensions of sensorimotor strength, we calculated Minkowski 3 perceptual strength (i.e., Minkowski distance at m = 3 of the six-dimension perceptual strength vector from the origin) and Minkowski 3 action strength (i.e., Minkowski distance at m =3ofthe five-dimension action strength vector from the origin).
Design and analysis Bayesian linear regressions were, as per Study 2a (using JSZ default priors, r scale = .354, with Bayesian adaptive sampling; JASP Team, 2019), but with different model comparisons. As per previous studies reported above, all data and analysis scripts are downloadable from the project ' s OSF page. Specifically, we created models to examine the effect of Minkowski 3 perceptual strength (Model 1), Minkowski 3 action strength (Model 2), and Minkowski 3 perceptual strength + Minkowski 3 action strength
simultaneously (Model 3), and quantified their evidence relative to the null model (containing the same lexical predictors as above) using Bayes factors. We then compared the relative evidence for action strength and perceptual strength as individual predictors (Model 2 vs. Model 1), and for the ability of action strength to predict lexical decision above and beyond perceptual strength (Model 3 vs. Model 1).","s13428-019-01316-z.pdf~Method~71"
"s13428-019-01316-z.pdf","Results and discussion",72,"Results and discussion
Both the perceptual and action strength Minkowski 3 composite variables independently predicted lexical decision performance across both the ELP and BLP datasets (see Table 5). Replicating previous findings (e.g., Connell & Lynott, 2010, 2012a, 2016a; Connell et al., 2018), perceptual strength accounted for 0.5% -1.6% of the variance in RTs and 0.5% -1.2% of the variance in accuracy. As an independent predictor, the effect size of action strength was overall fairly similar to that of perceptual strength: 0.6% -1.2% of variance in RTs, and 0.6% -1.3% of variance in accuracy. In three of the four dependent measures (ELP RT and accuracy, BLP accuracy), the effect of action strength was stronger than that of perceptual strength; only in the final dependent measure (BLP RT) was the effect of action strength weaker than that of perceptual strength. Combined entry of perceptual and action strength performed best, explaining 0.8% -2.0% of variance in RTs and 0.8% -1.8% of variance in accuracy. Moreover, since this combination of perceptual and action strength performed better than perceptual strength alone
Table 5 Bayesian linear regression results for English Lexicon Project (ELP) and British Lexicon Project (BLP) lexical decision response times (RTs) and accuracy, showing log Bayes factors (logBF) for model comparisons with composite Minkowski 3 perceptual strength and Minkowski 3 action strength","s13428-019-01316-z.pdf~Results and discussion~72"
"s13428-019-01316-z.pdf","Results and discussion",73,"Results and discussion
Table 5 Bayesian linear regression results for English Lexicon Project (ELP) and British Lexicon Project (BLP) lexical decision response times (RTs) and accuracy, showing log Bayes factors (logBF) for model comparisons with composite Minkowski 3 perceptual strength and Minkowski 3 action strength
RT, Model Comparison. = Null ( lexical variables). RT, English Lexicon Project ( N = 22,297).logBF = . RT, English Lexicon Project ( N = 22,297).R 2 = .591. RT, English Lexicon Project ( N = 22,297).∆ R 2 = . RT, British Lexicon Project ( N = 11,768).logBF = . RT, British Lexicon Project ( N = 11,768).R 2 = .485. RT, British Lexicon Project ( N = 11,768).∆ R 2 = . , Model Comparison. = Perceptual strength vs. null (BF10). , English Lexicon Project ( N = 22,297).logBF = 141.337. , English Lexicon Project ( N = 22,297).R 2 = .596. , English Lexicon Project ( N = 22,297).∆ R 2 = .005. , British Lexicon Project ( N = 11,768).logBF = 182.839. , British Lexicon Project ( N = 11,768).R 2 = .501. , British Lexicon Project ( N = 11,768).∆ R 2 = .016. , Model Comparison. = Action strength vs. null (BF20). , English Lexicon Project ( N = 22,297).logBF = 149.563. , English Lexicon Project ( N = 22,297).R 2 = .597. , English Lexicon Project ( N = 22,297).∆ R 2 = .006. , British Lexicon Project ( N = 11,768).logBF = 138.873. , British Lexicon Project ( N = 11,768).R 2 = .497. , British Lexicon Project ( N = 11,768).∆ R 2 = .012. , Model Comparison. = Perceptual + action strength vs. null (BF30). , English Lexicon Project ( N","s13428-019-01316-z.pdf~Results and discussion~73"
"s13428-019-01316-z.pdf","Results and discussion",74,"Results and discussion
Table 5 Bayesian linear regression results for English Lexicon Project (ELP) and British Lexicon Project (BLP) lexical decision response times (RTs) and accuracy, showing log Bayes factors (logBF) for model comparisons with composite Minkowski 3 perceptual strength and Minkowski 3 action strength
= 22,297).logBF = 207.094. , English Lexicon Project ( N = 22,297).R 2 = .599. , English Lexicon Project ( N = 22,297).∆ R 2 = .008. , British Lexicon Project ( N = 11,768).logBF = 230.205. , British Lexicon Project ( N = 11,768).R 2 = .505. , British Lexicon Project ( N = 11,768).∆ R 2 = .200. , Model Comparison. = Action vs. perceptual strength (BF21). , English Lexicon Project ( N = 22,297).logBF = 8.226. , English Lexicon Project ( N = 22,297).R 2 = . , English Lexicon Project ( N = 22,297).∆ R 2 = .001. , British Lexicon Project ( N = 11,768).logBF = - 43.966. , British Lexicon Project ( N = 11,768).R 2 = . , British Lexicon Project ( N = 11,768).∆ R 2 = - .004. , Model Comparison. = Perceptual + action strength vs. perceptual strength only (BF31). , English Lexicon Project ( N = 22,297).logBF = 65.757. , English Lexicon Project ( N = 22,297).R 2 = . , English Lexicon Project ( N = 22,297).∆ R 2 = .003. , British Lexicon Project ( N = 11,768).logBF = 47.366. , British Lexicon Project ( N = 11,768).R 2 = . , British Lexicon Project ( N = 11,768).∆ R 2 = .004. Accuracy, Model Comparison. = Null ( lexical variables). Accuracy, English Lexicon Project ( N = 22,297).logBF = . Accuracy, English Lexicon Project ( N =","s13428-019-01316-z.pdf~Results and discussion~74"
"s13428-019-01316-z.pdf","Results and discussion",75,"Results and discussion
Table 5 Bayesian linear regression results for English Lexicon Project (ELP) and British Lexicon Project (BLP) lexical decision response times (RTs) and accuracy, showing log Bayes factors (logBF) for model comparisons with composite Minkowski 3 perceptual strength and Minkowski 3 action strength
22,297).R 2 = .237. Accuracy, English Lexicon Project ( N = 22,297).∆ R 2 = . Accuracy, British Lexicon Project ( N = 11,768).logBF = . Accuracy, British Lexicon Project ( N = 11,768).R 2 = .286. Accuracy, British Lexicon Project ( N = 11,768).∆ R 2 = . , Model Comparison. = Perceptual strength vs. null (BF10). , English Lexicon Project ( N = 22,297).logBF = 66.951. , English Lexicon Project ( N = 22,297).R 2 = .242. , English Lexicon Project ( N = 22,297).∆ R 2 = .005. , British Lexicon Project ( N = 11,768).logBF = 98.251. , British Lexicon Project ( N = 11,768).R 2 = .298. , British Lexicon Project ( N = 11,768).∆ R 2 = .012. , Model Comparison. = Action strength vs. null (BF20). , English Lexicon Project ( N = 22,297).logBF = 81.216. , English Lexicon Project ( N = 22,297).R 2 = .243. , English Lexicon Project ( N = 22,297).∆ R 2 = .006. , British Lexicon Project ( N = 11,768).logBF = 105.771. , British Lexicon Project ( N = 11,768).R 2 = .299. , British Lexicon Project ( N = 11,768).∆ R 2 = .013. , Model Comparison. = Perceptual + action strength vs. null (BF30). , English Lexicon Project ( N = 22,297).logBF = 104.765. , English Lexicon Project ( N = 22,297).R 2 = .245. , English Lexicon Project ( N =","s13428-019-01316-z.pdf~Results and discussion~75"
"s13428-019-01316-z.pdf","Results and discussion",76,"Results and discussion
Table 5 Bayesian linear regression results for English Lexicon Project (ELP) and British Lexicon Project (BLP) lexical decision response times (RTs) and accuracy, showing log Bayes factors (logBF) for model comparisons with composite Minkowski 3 perceptual strength and Minkowski 3 action strength
22,297).∆ R 2 = .008. , British Lexicon Project ( N = 11,768).logBF = 7.520. , British Lexicon Project ( N = 11,768).R 2 = .304. , British Lexicon Project ( N = 11,768).∆ R 2 = .018. , Model Comparison. = Action vs. perceptual strength (BF21). , English Lexicon Project ( N = 22,297).logBF = 14.265. , English Lexicon Project ( N = 22,297).R 2 = . , English Lexicon Project ( N = 22,297).∆ R 2 = .001. , British Lexicon Project ( N = 11,768).logBF = 7.520. , British Lexicon Project ( N = 11,768).R 2 = . , British Lexicon Project ( N = 11,768).∆ R 2 = .001. , Model Comparison. = Perceptual + action strength vs. perceptual strength only (BF31). , English Lexicon Project ( N = 22,297).logBF = 37.814. , English Lexicon Project ( N = 22,297).R 2 = . , English Lexicon Project ( N = 22,297).∆ R 2 = .003. , British Lexicon Project ( N = 11,768).logBF = 46.023. , British Lexicon Project ( N = 11,768).R 2 = . , British Lexicon Project ( N = 11,768).∆ R 2 = .006","s13428-019-01316-z.pdf~Results and discussion~76"
"s13428-019-01316-z.pdf","Results and discussion",77,"Results and discussion
1286
in all cases, this means that action strength explained unique variance in lexical decision performance above and beyond perceptual strength.
Overall, these findings clearly demonstrate the continued utility of perceptual strength and the novel utility of action strength as predictors of lexical decision performance. We note that the two-parameter model of perceptual + action strength explained amounts of variance similar to that explained by the single-parameter model of sensorimotor strength in Study 2a. Nonetheless, there may be occasions when it is theoretically important to separate semantic information of a perceptual origin from that of an action origin. We therefore provide in the norms the overall composite variable of Minkowski 3 sensorimotor strength, as well as separate variables for Minkowski 3 perceptual strength and Minkowski 3 action strength.","s13428-019-01316-z.pdf~Results and discussion~77"
"s13428-019-01316-z.pdf","General discussion",78,"General discussion
The Lancaster Sensorimotor Norms present validated ratings of sensorimotor strength for almost 40,000 words. These ratings span 11 distinct dimensions of sensorimotor experience: six perceptual modalities (auditory, gustatory, haptic, interoceptive, olfactory, visual) and five action effectors (foot/leg, hand/arm, head, mouth, torso). The norms also include a further 12 cross-dimensional variables (e.g., exclusivity, dominant dimension, maximum strength, and the optimal composite variable of Minkowski 3 strength) for overall sensorimotor strength as well as for the perceptual and action components individually, plus information about what proportion of participants know each word well enough to rate its perceptual or action strength. The norms show good reliability, with strong levels of agreement across all dimensions, and their utility is demonstrated in capturing lexical decision behavior from two different databases. Altogether, the Lancaster Sensorimotor Norms provide over one million informative data points regarding the sensorimotor basis of semantics and conceptual grounding, and represent the largest set of psycholinguistic norms in English to date.
In comparison to previous norms, the Lancaster Sensorimotor Norms offer a number of advances. First is the sheer scale of the norms in terms of both lexical coverage and number of dimensions. Most semantic norms are available for only a few hundred (e.g., Amsel et al., 2012; Binder et al., 2016; Lynott & Connell, 2009, 2013; Paivio, Yuille, & Madigan, 1968) or a few thousand words/concepts (e.g., Cortese & Fugett, 2004; Juhasz & Yap, 2013; Scott, Keitel, Becirspahic, Yao, & Sereno, 2019; Tillotson et al., 2008). Indeed, there is generally an inverse relationship between the number of lexical items and the number of semantic variables normed, where multidimensional norms tend to have small coverage (e.g., Binder et al., 2016, provide ratings for 65
Behav Res (2020) 52:1271 -1291","s13428-019-01316-z.pdf~General discussion~78"
"s13428-019-01316-z.pdf","General discussion",79,"General discussion
dimensions on 535 concepts), whereas high-coverage norms tend to be for single dimensions (e.g., Brysbaert et al., 2014, provide ratings of concreteness for 39,954 concepts). By contrast, we provide norms for 11 sensorimotor dimensions (plus cross-dimensional variables) for 39,707 concepts, which is large enough to represent a full-sized adult vocabulary; 5 and comprehensive enough to span all perceptual modalities and action effectors involved in sensorimotor experience.
A second advance is that the norms provide a very rich source of information regarding the sensorimotor basis of semantics and conceptual grounding, and include novel dimensions of interoceptive strength, torso action strength, and separable mouth action and head action strength that have not previously been normed. As well as replicating previous findings on a larger scale, such as the dominance of visual vocabulary in English (Lynott & Connell, 2009, 2013; see also Winter et al., 2018) and the strong interrelationships between vision and touch and between taste and smell (Louwerse & Connell, 2011; Lynott & Connell, 2009, 2013), the breadth of dimensions also generates new insights into the sensorimotor basis of concepts. For example, interoceptive strength is highly important to abstract, particularly emotional, concepts (Connell et al., 2018). Or action verbs such as run or carry , that might seem to relate only to the foot/leg or hand/arm, often involve a moderate amount of torso action. Moreover, the present norms also offer important new insights regarding relationships between sensorimotor dimensions and their role in different concept types. For instance, auditory strength is negatively related to all dimensions except for head and mouth strength, where their positive relationship is primarily due to the importance of listening in speech and communication. By contrast, the strength of torso action is positively related to all dimensions except auditory and gustatory strength, highlighting its relevance to all but sound-related and taste-related concepts.","s13428-019-01316-z.pdf~General discussion~79"
"s13428-019-01316-z.pdf","General discussion",80,"General discussion
Finally, we identified a new composite variable that aggregates the information from the full 11-dimension sensorimotor profile in an optimal way to predict implicit access to semantic information: Minkowski 3 strength. In previous uses of perceptual strength norms across hundreds of items (Connell & Lynott, 2012a), we identified maximum perceptual strength (i.e., the strength in the dominant dimension) as the best single aggregate variable in predicting lexical decision performance (Study 2a). Although max strength continued to perform very well in the present analyses of tens of thousands of items, it
5 According to estimates by Brysbaert, Stevens, Mandera, and Keuleers (2016), typical adult native speakers of English in their mid-30s (i.e., the average age of the participants in our norms) would know approximately 46,000 lemmas, at a shallow level of knowing that a word exists. A subset of these lemmas would be known at a deeper level that involves some understanding of what the word means. Our norms for 39,707 lemmas required knowledge at a relatively deep level in order to rate the perceptual or action experience of the referent concept, and so provide reasonably generous coverage of a full-sized adult vocabulary.
Behav Res (2020) 52:1271 -1291
1287","s13428-019-01316-z.pdf~General discussion~80"
"s13428-019-01316-z.pdf","General discussion",81,"General discussion
was outperformed by the Minkowski 3 measure: a vectorbased distance metric that allows nondominant dimensions to have an attenuated influence on the final score, according to how close their values are to that of the dominant dimension. It is notable that Minkowski 3 emerged as the best aggregate predictor of sensorimotor semantic facilitation, as Minkowski values around 3 have previously been identified as the optimal model for integrating multiple perceptual cues (To et al., 2011). Although Minkowski values in the range of 3 -4 have previously been used in studies of visual perception (Quick, 1974; Robson & Graham, 1981), To and colleagues provided evidence that Minkowski values between 2.5 and 3 actually represent a general principle for perceptual integration and may reflect the summation of neural responses to perceptual stimuli. From the perspective of the present norms, it should be noted, of course, that one loses much information by trying to reduce a multidimensional representation to a single value, and considering individual perceptual modalities and action effectors is critical to a variety of theoretical questions (e.g., Connell & Lynott, 2014a; Connell et al., 2018; Winter et al., 2018). Nonetheless, Minkowski 3 strength provides a powerful tool when the necessity arises.","s13428-019-01316-z.pdf~General discussion~81"
"s13428-019-01316-z.pdf","General discussion",82,"General discussion
In terms of processing and representing concepts, what does it mean that Minkowski 3 outperforms other measures in predicting lexical processing behavior? Firstly, it suggests that in modeling human performance we need to take into account multiple sensorimotor dimensions, and that reliance on a single, dominant dimension of perception or action experience is inadequate for capturing performance. Second, it suggests that although all dimensions are important to some extent, not all dimensions should be treated equally. In other words, greater weighting should be placed on higher-value dimensions (i.e., those for which sensorimotor experience is strongest), but weaker dimensions should still be taken into account. If an equal weighting of all dimensions were the best approach, then the ' summed strength ' measure would have emerged as a better predictor in Study 2a. Similarly, if the best approach were to ignore or severely attenuate weaker dimensions, then measures such as maximum strength or Minkowski 10 would have emerged as better predictors. Finding that Minkowski 3, in its weighted balance of strong and weak dimensions, is a good predictor of lexicalprocessing performance may provide some insights for those interested in the sensorimotor correspondence of word meaning. For example, it may suggest a starting point for computational models in how best to combine signals from multiple sensorimotor regions of the brain to create composite semantic neural representations, that approximate the neural patterns observed in humans. As well as applying elements such as Minkowski 3 weightings to sensorimotor representations, there may be other ways in which the present work can act as a constraint on future theory development. For example, an understanding of the complex correlations between perceptual
modalities and action effectors may constrain accounts of how attention may be implicitly allocated, switched, or shared in order to make optimal use of neural resources to meet task demands (e.g., Connell & Lynott, 2010, 2014a; Spence, Nicholls, & Driver, 2001). To make progress in this area, future theories will need to account for observed modalityspecific effects, and cross-modal or cross-effector correspondences that impact how we process language and indeed the world around us.","s13428-019-01316-z.pdf~General discussion~82"
"s13428-019-01316-z.pdf","General discussion",83,"General discussion
In conclusion, the Lancaster Sensorimotor Norms provide a valuable resource for researchers across a variety of fields. Use of these norms as semantic variables, whether as an aggregate measure of sensorimotor strength or as modality- and effector-specific ratings, will inform psycholinguistic models of word recognition and language processing (e.g., Connell & Lynott, 2016a; Estes, Verges, & Adelman, 2015; Speed & Majid, 2017; see also Connell & Lynott, 2016b, for a review). The parallels between the sensorimotor dimensions in the present norms and specific brain regions related to perceptual and action processing mean that close examination of the roles and interactions of each dimension will be able to inform theories of grounded representation and embodied semantics (e.g., Connell et al., 2018; Lievers & Winter, 2018; Rey, Riou, Vallet, & Versace, 2017). For instance, we are currently using the norms to examine emergent conceptual structure from sensorimotor knowledge (Connell, Brand, Carney, Brysbaert, Banks, & Lynott, 2019; Connell, Brand, Carney, Brysbaert, & Lynott, 2019), and the role of sensorimotor experience in categorization (Banks, Wingfield, & Connell, 2019; van Hoef, Connell, & Lynott, 2019). Furthermore, the large size of the norms makes them amenable to some machine learning applications, such as using sensory language to identify early markers of clinical conditions (e.g., Kernot, Bossomaier, & Bradbury, 2017) or to inform recommender algorithms of therapeutic texts (Carney & Robertson, 2019). We hope the work presented here will prove useful for any researchers interested in the sensorimotor basis of word meaning and concepts.
Open Practices Statement The Lancaster Sensorimotor Norms dataset, additional data, materials, analysis, and scripts for all studies are available at https://osf.io/7emr6/. The norms dataset is also available as a searchable database (https://www. lancaster.ac.uk/psychology/lsnorms/).","s13428-019-01316-z.pdf~General discussion~83"
"s13428-019-01316-z.pdf","General discussion",84,"General discussion
Author Note This research was supported by the Leverhulme Trust, UK (Grant RPG-2015-412 to D.L., L.C., and M.B.) and the European Research Council (ERC) under the European Union ' s Horizon 2020 research and innovation program, under Grant Agreement No. 682848 to L.C. We thank R. Meers and P. Mei, who provided help with data collection and quality control during the project, and D. Balota, for permitting us to include data from the English Lexicon Project in our deposited
1288
analysis files. We also thank B. Winter and two anonymous reviewers for helpful comments and feedback on our initial submissions.
Open access note All images and data used in this article are licensed under a Creative Commons Attribution 4.0 International License (CC-BY), which permits use, sharing, adaptation, distribution, and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. Any images or other third-party material in this article are included in the article ' s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article ' s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.","s13428-019-01316-z.pdf~General discussion~84"
"s13428-019-01316-z.pdf","Appendix",85,"Appendix
Below are the variables included in the Lancaster Sensorimotor Norms dataset.
Word : Lemma (concept) presented to participants for rating Auditory.mean : Auditory strength: mean rating (0 -5) of
how strongly the concept is experienced by hearing
Gustatory.mean: Gustatory strength: mean rating (0 -5) of how strongly the concept is experienced by tasting
Haptic.mean: Haptic strength: mean rating (0 -5) of how strongly the concept is experienced by feeling through touch
Interoceptive.mean: Interoceptive strength: mean rating (0 -5) of how strongly the concept is experienced by sensations inside the body
Olfactory.mean: Olfactory strength: mean rating (0 -5) of how strongly the concept is experienced by smelling
Visual.mean: Visual strength: mean rating (0 -5) of how strongly the concept is experienced by seeing
Foot_leg.mean: Foot action strength: mean rating (0 -5) of how strongly the concept is experienced by performing an action with the foot/leg
Hand_arm.mean: Hand action strength: mean rating (0 -5) of how strongly the concept is experienced by performing an action with the hand/arm
Head.mean: Head action strength: mean rating (0 -5) of how strongly the concept is experienced by performing an action with the head excluding mouth
Mouth.mean: Mouth action strength: mean rating (0 -5) of how strongly the concept is experienced by performing an action with the mouth/throat
Torso.mean: Torso action strength: mean rating (0 -5) of how strongly the concept is experienced by performing an action with the torso
Behav Res (2020) 52:1271 -1291
Auditory.SD: Standard deviation of auditory strength ratings
Gustatory.SD: Standard deviation of gustatory strength ratings
Haptic.SD: Standard deviation of haptic strength ratings Interoceptive.SD: Standard deviation of interoceptive strength ratings
Olfactory.SD: Standard deviation of olfactory strength ratings
Visual.SD: Standard deviation of visual strength ratings Foot_leg.SD: Standard deviation of foot action strength ratings
Hand_arm.SD: Standard deviation of hand action strength ratings
Head.SD: Standard deviation of head action strength ratings
Mouth.SD: Standard deviation of mouth action strength ratings
Torso.SD: Standard deviation of torso action strength ratings","s13428-019-01316-z.pdf~Appendix~85"
"s13428-019-01316-z.pdf","Appendix",86,"Appendix
Max_strength.perceptual: Perceptual strength in the dominant modality (i.e., highest strength rating across six perceptual modalities)
Minkowski3.perceptual: Aggregated perceptual strength in all modalities in which the influence of weaker modalities is attenuated, calculated as Minkowski distance (with exponent 3) of the six-dimension vector of perceptual strength from the origin.
Exclusivity.perceptual: Modality exclusivity of the concept; the extent to which a concept is experienced though a single perceptual modality (0 -1, typically expressed as a percentage), calculated as the range of perceptual strength values divided by their sum
Dominant.perceptual: Perceptual modality through which the concept is experienced most strongly (i.e., with highest perceptual strength rating)
Max_strength.action: Action strength in the dominant effector (i.e., highest strength rating across five action effectors)
Minkowski3.action: Aggregated action strength in all effectors in which the influence of weaker effectors is attenuated, calculated as Minkowski distance (with exponent 3) of the five-dimension vector of action strength from the origin.
Exclusivity.action: Effector exclusivity of the concept; the extent to which a concept is experienced though a single action effector (0 -1, typically expressed as a percentage), calculated as the range of action strength values divided by their sum
Dominant.action: Action effector through which the concept is experienced most strongly (i.e., with highest action strength rating)
Max_strength.sensorimotor: Sensorimotor strength in the dominant dimension (i.e., highest strength rating across 11 sensorimotor dimensions)
Behav Res (2020) 52:1271 -1291
1289
Minkowski3.sensorimotor: Aggregated sensorimotor strength in all dimensions where the influence of weaker dimensions is attenuated, calculated as Minkowski distance (with exponent 3) of the 11-dimension vector of sensorimotor strength from the origin.","s13428-019-01316-z.pdf~Appendix~86"
"s13428-019-01316-z.pdf","Appendix",87,"Appendix
Exclusivity.sensorimotor: Sensorimotor exclusivity of the concept; the extent to which a concept is experienced though a single sensorimotor dimension (0 -1, typically expressed as a percentage), calculated as the range of sensorimotor strength values divided by their sum
Dominant.sensorimotor: Sensorimotor dimension through which the concept is experienced most strongly (i.e., with highest sensorimotor strength rating)
N_known.perceptual: Number of participants in perceptual strength norming who knew the concept well enough to provide valid ratings (i.e., as opposed to selecting the ' don ' t know ' option)
List_ N. perceptual: Number of valid participants in perceptual strength norming who completed the item list featuring the concept (i.e., who were presented with the concept for rating)
Percent_known.perceptual: Percentage of participants (0 -1) in perceptual strength norming who knew the concept well enough to provide valid ratings, calculated as N_known.perceptual divided by List_N.perceptual
N_known.action: Number of participants in action strength norming who knew the concept well enough to provide valid ratings (i.e., as opposed to selecting the ' don ' t know ' option)
List_ N. action: Number of valid participants in action strength norming who completed the item list featuring the concept (i.e., who were presented with the concept for rating)
Percent_known.action: Percentage of participants (0 -1) in action strength norming who knew the concept well enough to provide valid ratings, calculated as N_known.action divided by List_N.action
Mean_age.perceptual: Average age of participants in perceptual strength norming who completed the item list featuring the concept (i.e., who were presented with the concept for rating)
Mean_age.action: Average age of participants in action strength norming who completed the item list featuring the concept (i.e., who were presented with the concept for rating)
List#.perceptual: Code number of the item list in perceptual strength norming that featured the concept
List#.action: Code number of the item list in action strength norming that featured the concept","s13428-019-01316-z.pdf~Appendix~87"
"s13428-019-01316-z.pdf","Appendix",88,"Appendix
Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http:// creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.","s13428-019-01316-z.pdf~Appendix~88"
"29915007","Introduction",1,"1. Introduction Odours give rise to primary sensory experiences. Every time we inhale we use our sense of smell to make sense of our environment.","29915007~Introduction~1"
"29915007","Introduction",2,"Odours are used to detect and identify foods, to avoid environmental hazards, and they enable social communication [1,2]. We can identify the source of a gas leak or navigate towards (or away from!) a department store perfume counter by using our sense of smell alone [3].","29915007~Introduction~2"
"29915007","Introduction",3,"In fact, people can track a 10 m long scent trail of chocolate through a field [4]. Our ability to detect odours is so keen that the odorant ethyl mercaptan (which gives gas its distinctive smell) can be detected at concentrations equivalent to three drops diluted in an Olympic-size swimming pool [5]. Despite evidence of humans having such keen noses, it has been claimed that like other abstract domains—such as time or emotion—odours are difficult to conceptualize.","29915007~Introduction~3"
"29915007","Introduction",4,"We may be able to detect whether an odour is present or not, or follow it to its source using intensity gradients, but many doubt we can think olfactorily. The Scottish philosopher Thomas Reid claimed: ‘It is evidently ridiculous, to ascribe to it [the smell]1 figure, colour, extension, or any other quality of bodies. He cannot give it a place, any more than he can give a place to melancholy or joy: nor can he conceive it to have any existence but when it is smelled.","29915007~Introduction~4"
"29915007","Introduction",5,"So that it appears to be a simple and original affection or feeling of the mind, altogether inexplicable and unaccountable. It is indeed impossible that it can be any body: It is a sensation; and a sensation can only be in a sentient thing.’ [6].","29915007~Introduction~5"
"29915007","Introduction",6,"Olfactory notions, indeed, seem difficult to conjure at will. When asked to imagine a pan of onions frying on a stove, only 3% of people say they are unable to see the onions, but a striking 57% say they are unable to smell them [7]. Similarly, when asked to imagine a specific object—for example, a rose—people rate the odour experience as having the lowest vividness and clarity in comparison to the other modalities [8,9].","29915007~Introduction~6"
"29915007","Introduction",7,"Most striking, perhaps, is the finding that people rarely report olfactory imagery from their spontaneous conscious experiences: when participants are asked to report imagery they experience on the hour, every hour, visual images abound, occurring around 60% of the time; but olfactory imagery appears as little as 1% of the time [10]. This suggests that odour representations are fragile.Similarly, odours appear difficult to verbalize [5,11–16]. Even when presented with familiar odours, speakers struggle to name them on the basis of smell alone [14–16].","29915007~Introduction~7"
"29915007","Introduction",8,"When English speakers do name odours, they typically refer to their source (e.g. smells like lemon), suggesting that when they are able to identify an odour they think of it in concrete terms [17]. That is, odours trigger bounded, cohesive object concepts [18]. In fact, Hans Henning claimed: ‘olfactory abstraction is impossible.","29915007~Introduction~8"
"29915007","Introduction",9,"We can easily abstract the common shared colour—i.e. white—of jasmine, lily-of-the-valley, camphor and milk, but no man can similarly abstract a common odour by attending to what they have in common and setting aside their differences' [19, p. 66]. This view has been challenged recently by cross-cultural research.","29915007~Introduction~9"
"29915007","Introduction",10,"In some communities instead of talking about odours in terms of objects, dedicated vocabulary for referring to odour qualities is used instead [16,20–23]. These terms have been coined ‘abstract’ because they do not refer to any specific source. For example, in the language Jahai—spoken by a hunter-gatherer community in the rainforest of the Malay Peninsula—the term cŋɛs is used to refer to stinging sorts of smells associated with petrol, smoke, and various insects and plants, while pl?","29915007~Introduction~10"
"29915007","Introduction",11,"ʔeʕŋ refers to bloody, fishy, meaty sorts of smells. There are around a dozen smell terms in Jahai: they are monolexemic, stative verbs; they do not refer to a specific or restricted class of objects; they are also psychologically salient, appearing in everyday conversation and child speech [16,20]. Under experimental conditions, Jahai speakers depart from English speakers in how they encode odours too.","29915007~Introduction~11"
"29915007","Introduction",12,"Majid & Burenhult [16] gave 10 male Jahai participants and 10 age- and gender-matched English participants common odours (familiar to Westerners, e.g. chocolate, petrol) and asked speakers to name them. They found that English speakers indeed used source-based, concrete vocabulary, while Jahai speakers used abstract odour terms. In addition, English participants had very low agreement in how they described odours, whereas Jahai participants had significantly higher agreement.At the same time, it has been suggested that the main evolutionary function of the olfactory system is to detect odour pleasantness, so that people universally perceive the same odours as pleasant versus unpleasant on the basis of the physical structure of the odour molecule [24–26].","29915007~Introduction~12"
"29915007","Introduction",13,"This raises a puzzle because in a separate line of inquiry researchers have proposed that abstract concepts are more detached from sensory experience than concrete concepts, and more variable cross-linguistically [27,28]. If Westerners truly think about odours in terms of concrete objects, whereas some small-scale communities think about odours as abstract qualities, might there be knock-on consequences for their underlying odour concepts? Consistent with this proposal, cross-modal associations between odours and colours have been shown to differ as a function of how the odour is described: odours described using source-based terms give rise to more consistent and canonical colour associations (e.g. banana odour → ‘smells like banana’ → colour yellow) than those described with abstract terms (e.g. musty), which instead have less strong colour associations [17].","29915007~Introduction~13"
"29915007","Introduction",14,"This suggests abstract odour vocabulary is less grounded in multi-modal sensory experience. Accordingly, this predicts that Jahai participants who describe odours with abstract vocabulary might have weaker emotional associations to odours. Conversely, abstract words are said to be more emotionally-loaded [29,30], which would predict that Jahai participants should evince stronger emotional reactions to odours as a function of their specific linguistic encoding.The current paper re-visits the issue of olfactory abstraction across cultures, and investigates its interaction with emotion.","29915007~Introduction~14"
"29915007","Introduction",15,"We asked a larger sample of men and women in Jahai and Dutch to name monomolecular odorants, while measuring both verbal (odour names and reaction times) and non-verbal (facial expression) responses. We used ‘abstract’ monomolecular odorants (not clearly associated with any concrete source) to investigate whether this would lure Western participants to produce more ‘abstract’ verbal responses; thus testing task parameters for abstraction in odour naming [31]. In addition, we sought to establish whether Jahai and Dutch participants had ‘universal’ non-verbal responses to odorants or whether emotional reactions varied cross-linguistically.","29915007~Introduction~15"
"29915007","Introduction",16,"That is, do Jahai and Dutch participants find the same odours pleasant and unpleasant (as measured by their facial expressions), but only later differentiate in terms of their verbal responses; or do the two groups differ in their initial, affective reactions to odours too?","29915007~Introduction~16"
"29915007","Methods",1,"2. Methods(a)Participants Participants were 30 (15 women) native speakers of Jahai. Age could only be estimated for most people, but ranged from 15 to 64 years; approx.","29915007~Methods~1"
"29915007","Methods",2,"M = 32 years. Thirty Dutch participants were matched to Jahai for age and gender; with equal numbers of men and women, age M = 32 years (range 16–64). Jahai and Dutch did not differ by age t(58) = 0.18, p = 0.99.","29915007~Methods~2"
"29915007","Methods",3,"All Jahai still pursue traditional foraging, although they reside in a resettlement village much of the time, and so are exposed to modernity. They were tested in Air Banun, Hulu Perak district, Peninsular Malaysia. The Dutch participants live a typical urbanized Western lifestyle.","29915007~Methods~3"
"29915007","Methods",4,"They were tested in Nijmegen, The Netherlands. Although participants were matched as closely as possible, there were nevertheless substantial differences between the groups, including in schooling and multilingualism. Seventeen Jahai participants had no schooling, and the rest had only 1–6 years of primary school education (in Malay).","29915007~Methods~4"
"29915007","Methods",5,"Most Jahai speak Malay, and many are also fluent in Temiar (a related Aslian language). All Dutch participants were educated to at least high school level; 10 participants also had university-level education. All (but one) Dutch participants were also fluent in English, and many spoke at least two additional languages (including German, French, Greek, Chinese, etc.).","29915007~Methods~5"
"29915007","Methods",6,"All Jahai men, and more than half the women smoked; only eight Dutch men and two Dutch women reported they smoked.(b)Stimuli Since most commercially available smell tests are primarily comprised of odours of pleasant fruity and flowery notes, we devised a novel set of test odours constructed to better match what we knew about the odour words used by the Jahai. These included odours for more varied unpleasant smells. Specifically, we selected a set of monomolecular odours (n = 37),2 which apart from fruity and flowery smells, also included volatiles associated with, e.g. animals, decay, meat, blood, mould and faeces (table 1).","29915007~Methods~6"
"29915007","Methods",7,"The odorants were soaked into the cotton filament of a plastic marker pen ‘Sniffin' Stick’; the cap was removed by an experimenter during trials, and the felt-tip placed in front of participants' nostrils. Table 1. Odorants with their unique numerical identifier assigned by the Chemical Abstracts Service (CAS), with their associated chemical name and brief descriptors.number CAS#namedescriptor2513-86-0acetoinbutter, cream4142-62-1hexanoic acidfatty, fruity679-09-4nonanoic acidcheesy, pungent8137-00-8sulforolmeaty, beefy975-50-3trimethyl aminefishy125655-61-8bornyl acetatebalsamic, woody1380-71-7cyclotene hydratecaramel15104-67-6gamma-undecalactonepeachy fruity18290-37-9pyrazinenutty2087-44-5beta-caryophyllenespicy, clove21123-25-1diethyl succinatefruity22123-32-02,5-dimethyl pyrazinechocolatey23105-54-4ethyl butyratepineapple, fruity2455704-78-4meaty dithianemeaty25135-79-5isopropyl quinolinegreen271222-05-5musk gx 100%musk2916409-46-4menthyl isovalerategreen woody sweet3278-96-61-amino-2-propanolfishy3371-41-0amyl alcoholwiney, yeasty, fermented3483-34-1skatolefaecal3596-15-12-methyl butyl aminefishy36103-09-3isooctyl acetateearthy37109-05-72-methyl piperidinefishy391878-18-82-methyl-1-butane thiolbloody, sulphurous404861-58-92-pentyl thiophenebloody (fruity?)","29915007~Methods~7"
"29915007","Methods",8,"4118138-04-02,3-diethyl-5-methylpyrazinemusty, nutty, hazelnut4459558-23-5para-cresyl caprylatefaecal4599-87-6para-cymeneterpenic, rancid, woody, citrus, spicy463391-86-41-octen-3-olearthy, mushroom4745019-28-14-methyl nonanoic acidmeaty495333-83-51-(2-thienyl) butanonegrilled meat51625-33-23-penten-2-onefishy, fruity? 5380-56-8alpha-pinenepiney543681-71-8z3 hexenyl acetatesharp fruity-green55106-25-2nerolsweet, floral, rose56122-03-2cuminaldehydegreen, herbal, spicy, characteristic cumin5776-22-2camphorcamphoraceous(c)Procedure Participants were tested in their native language, i.e. Jahai and Dutch.","29915007~Methods~8"
"29915007","Methods",9,"There were two experimenters: one who operated a camera directly opposite the participant; and a second who presented the participant with the odorants, who sat at 90° to the participant. Odours were presented one at a time with at least 60 s between different odorants. Participants were told to keep their head still while the experimenter brought the Sniffin' Stick to their nose so they could smell it, and then said ‘What smell is this?’: in Jahai  (literally, what smell 3S DEM ‘what smell it this’); in Dutch Welke geur is dit?","29915007~Methods~9"
"29915007","Methods",10,"(literally, ‘what smell is this?’). The participant could request to smell an odour again as many times as they wished, and were frequently asked if they would like to take a longer break. The whole session took approximately 1 h to run per person.(d)Coding After testing, recordings were imported into ELAN [32].","29915007~Methods~10"
"29915007","Methods",11,"ELAN enables annotation of both verbal and non-verbal responses with high timing accuracy in a single platform. The full verbal responses to each odorant were transcribed, and main contentful responses coded. For example, from the full Dutch response: Ja, het heeft iets kaneligs maar ik kan, nee, ik kan, eh, niet specifiek, eh, zeggen wat het is.","29915007~Methods~11"
"29915007","Methods",12,"‘Yes, it is something cinnamon-like, but I can, no, I can, erm, not specifically, erm, say what it is.’; ‘cinnamon’ was coded as the main response, which is a source-based description. Onset and offset of transcriptions were time-aligned with speech. Time to name an odour (in ms) was measured from when the Sniffin' Stick was closest to the nose to when the participant began to speak.","29915007~Methods~12"
"29915007","Methods",13,"Ideally exact sniff measurements would have been taken but this was not practical in the field, and more critically would have disrupted facial expression coding. Separately, a trained FACS coder (Facial Action Coding System [33]) annotated the non-verbal facial responses to each odour. For the current purposes, we focus on facial muscle movements (action units, AU), previously identified as being relevant for ‘disgust’ or ‘pleasure’ [34,35], or which were recurrent in the dataset (table 1).","29915007~Methods~13"
"29915007","Methods",14,"Our focus was on the first appraisals, and so only those AUs that began within 2 s of the Sniffin' Stick being held to the nose were coded.Once transcribed and coded, data were extracted from ELAN and the following dependent variables were examined: (i) type of responses given to odorants; (ii) length of descriptions to odorants for Jahai and Dutch; (iii) timing of responses—i.e. how long participants took to give a verbal response measured from when the Sniffin' Stick was held at the nose; (iv) agreement in descriptions across communities; and (v) facial expressions to odours.","29915007~Methods~14"
"29915007","Results",1,"3. Results(a)Type of response There was a clear qualitative distinction between Jahai and Dutch responses (figure 1). Out of 1110 opportunities to describe odours (37 stimulus × 30 participants), Jahai participants produced 22 distinct response types: 19 were abstract smell terms, and these made up 99.5% of all tokens.","29915007~Results~1"
"29915007","Results",2,"In addition, there were 3 source-based terms (referring to types of plants; 0.3%); 1 evaluative expression (be good; 0.1%); and only once did 1 participant produce no verbal descriptor (0.1%). Figure 1.( Top panel) Types of strategies used to describe odours by Jahai and Dutch participants, and (bottom panel) time taken to name odours by language and participant.","29915007~Results~2"
"29915007","Results",3,"Jahai speakers use overwhelmingly abstract odour terms and take around 2 s to name odours; Dutch participants use predominantly concrete descriptors and take around 13 s to name odours.In contrast, Dutch participants produced 707 distinct responses, and more diverse strategies. Participants said they didn't know what the odour was 3.7% of the time, and were able only to say that it was familiar in some way 3.9% of the time; or they produced an evaluative response 5.7% of the time (e.g. wow, godver ‘damn’, gek ‘crazy’). The dominant contentful response was to refer to a concrete source (e.g. bloemen ‘flowers’; ammoniak ‘ammonia’, mest ‘manure’, etc.); this category consisted of 557 different tokens and 64.7% of all responses.","29915007~Results~3"
"29915007","Results",4,"Another strategy was to refer to a specific scenario (4.7%) (e.g. als je d'r langsfietst of achter de vuilniswagen staat niet d'r bovenop ‘if you ride along or stand behind a garbage truck, but not right on top of it’; eten dat lekker smaakt maar als het in de pot bij oma ligt dan stinkt het ‘food that tastes good but if it is in the pot at granny's then it stinks’; huis waar niet veel gelucht wordt ‘house that isn't aired’). Thereafter, responses could be said to involve some degree of abstraction: for example, participants used a crossmodal metaphor of some type 9.2% of the time (e.g. scherp ‘sharp’, zoet ‘sweet’, warm ‘warm’); or gave a generic category for some odours (2.3%) (e.g. chemisch ‘chemical’, synthetisch ‘synthetic’, natuurlijk ‘natural’, organisch ‘organic’), in which they referred to a type of odours; or they referred not the quality of the smell but its intensity (5.7% of responses). There were only five abstract odour terms used throughout the study (stinkt ‘smelly’; stinkt niet ‘not smelly’; muf ‘musty’; ranzig ‘rancid smell’; and weeïg ‘sickly smell’) and these made up only 2.2% of all responses.(b)Length of response Further confirming the qualitative differences between Jahai and Dutch verbal responses, we found that Jahai speakers gave a single abstract term the majority of the time, and as such the average length of their response was much shorter than Dutch responses.","29915007~Results~4"
"29915007","Results",5,"Prior research has established that orthographic length correlates highly with phonetic length, even for languages with irregular spelling [36]; as such we took orthographic length as a proxy for speech length. Arguably a strictly phonemic representation of Dutch responses, comparable to the Jahai orthography [37], would result in somewhat shorter estimates than those measured here, but the differences between languages were nevertheless substantial: Jahai responses were on average five characters long, whereas Dutch responses were 85 characters. Using the lme4 package [38,39], linear mixed-effects models were fitted to the log-transformed data (which were otherwise skewed).","29915007~Results~5"
"29915007","Results",6,"Language was treated as a fixed effect, with participants and items as random effects; p-values were obtained by likelihood ratio tests of the model with and without language as a factor. We found that language had a significant effect on the length of responses (measured in characters) χ2(1) = 3660, p < 0.0001.(c)Time of response Not only were the Jahai more succinct in naming odours, they were quicker too: on average Jahai participants took around 2 s to give a verbal response, whereas Dutch participants took more than 13 s (figure 1). Dutch participants took even longer if time to produce a contentful response was measured (e.g. ‘flowers’; as opposed to saying ‘I don't know’ or equivalent).","29915007~Results~6"
"29915007","Results",7,"Linear mixed-effects models were fitted (as above) to the log-transformed time (in ms) that it took participants to name each odour. Four datapoints were clearly outliers based on visual inspection of the data (0.18%) and were removed from both analyses reported below. Language had a significant effect on time to produce a first verbal response χ2(1) = 2411, p < 0.0001, and first contentful response χ2(1) = 2689, p < 0.0001.","29915007~Results~7"
"29915007","Results",8,"In fact, to produce the first contentful response, Jahai speakers took M = 2727 ms, whereas Dutch speakers took 17 280 ms.(d)Agreement Jahai participants agreed more with one another in how to describe each stimulus than Dutch speakers did. We calculated agreement across speakers in naming each odorant separately for Jahai and Dutch using Simpson's Diversity Index [40], following [16]. We asked whether despite differences in linguistic strategies, there was nevertheless consensus when odours were described.","29915007~Results~8"
"29915007","Results",9,"Language had a significant effect on agreement calculated over first responses χ2(1) = 122, p < 0.0001, and when taking all responses into consideration χ2(1) = 131, p < 0.0001. That is, Jahai participants agreed more with each other in how to describe odours, even when all responses Dutch participants gave were considered in comparison.Next, we examined the data using a dual-factoring technique—correspondence analysis (ca package in R [41])—which enables visualization of associations between categorical variables. Figure 2 (a) depicts the relationship between verbal labels3 (red) and odorants (blue; see table 1 for list of odorants).","29915007~Results~9"
"29915007","Results",10,"In these plots, the more two odorants are called by the same term, the closer they are plotted together. Similarly, the more often terms are used for similar odorants, the closer they are plotted. The Dutch data showed weak structure, as reflected in the poor model fit (only 18.5% of the variance in the data are captured by the first two dimensions).4 Verbal responses mostly cluster on 0, suggesting weak associations between specific labels and particular odorants.","29915007~Results~10"
"29915007","Results",11,"Odour stimuli were, nevertheless, dispersed because they were rarely called by the same term. Figure 2. Correspondence analysis plots of (a) odour descriptions (red) and odorants (blue) for Jahai and Dutch and (b) facial expression action units (AUs) by odorants.","29915007~Results~11"
"29915007","Results",12,"See table 1 for full description of odorants and table 2 for description of AUs. Table 2. Action units (AUs) coded for facial expressions, their brief description, and correlation values (Pearson r) across odorants between Jahai and Dutch participants (with p one-tailed; df = 35).action unitdescriptionrp AUs associated with pleasant emotions AU1inner brow raise0.0330.423 AU2outer brow raise−0.0870.305 AU6cheek raise0.2950.038 AU12lip corner pull0.3600.014 AU17chin raise0.2340.082AUs associated with unpleasant emotions AU4brow lower0.4610.002 AU7lid tight0.5200.000 AU9nose wrinkle0.2920.040 AU10upper lip raise0.2900.041 AU15lip corner depress0.1050.268 AU5upper lid raise−0.0450.396The Jahai name∼odorant plot looks strikingly different (figure 2a).","29915007~Results~12"
"29915007","Results",13,"The first two dimensions explained 41.7% of the variance. There was a clearer correspondence between labels and odorants. The left-hand side depicts terms that prototypically refer to pleasant odours, while the right features terms prototypically referring to unpleasant odours (interpreted according to the semantics of the Jahai terms [20]).","29915007~Results~13"
"29915007","Results",14,"Correspondingly, odorants (blue) on the left are classified by Jahai terms as more pleasant than those on the right. So, musk (27), nerol (described in the literature as sweet, floral; 55), alpha-pinene (piney; 53), diethyl succinate (fruity; 21), champher (camphoreous; 57); 3-penten-2-one gamma-undecalactone (peachy fruity; 15), etc. (described in the literature as both fishy and fruity; 51) are all described with terms for fragrant-type odour words. In the same space we also find 4-methyl nonanoic acid (meaty; 47), 1-amino-2-propanol (fishy; 32), 2-methyl piperidine (fishy; 37), which are described with these general fragrant terms, and specifically cŋəs, which could be glossed as ‘edibly fragrant’.","29915007~Results~14"
"29915007","Results",15,"Note, however, that other odorants that have previously been described in the olfactory literature as ‘fishy’ and ‘meaty’ load on the other side of the plot, and are described by the Jahai with terms best glossed as ‘stinking’; e.g. haʔɛ̃t: trimethyl amine (9), meaty dithiane (24), etc. This is likely due to the subtle differences in the odour characteristics; e.g. trimethyl amine is said to be rancid and sweaty, as well as fishy in odour.(e)Emotion From the ELAN coding of facial expressions, we identified whether each participant displayed the target AU (table 2) for each odorant. We then aggregated Jahai (n = 30) and Dutch (n = 30) responses for each AU separately, and examined whether the two groups displayed similar emotional reactions to odorants, or not.","29915007~Results~15"
"29915007","Results",16,"To test this, we correlated summed AUs displayed by each group: if Jahai and Dutch participants have similar responses to odorants, then facial expressions ought to covary. Table 2 shows that AUs associated with negative facial expressions [34,35] for odorants correlated for the Jahai and Dutch (as reflected in brow lower, lid tight, nose wrinkle and upper lip raise); as did positive facial expressions (i.e. cheek raise and lip corner pull), albeit less clearly (see also figure 2). This suggests that despite differential linguistic categorization of odours, the two groups nevertheless converge on their initial affective responses.","29915007~Results~16"
"29915007","Conclusion",1,"4. Conclusion Olfactory abstraction varies across cultures: while Dutch participants confirmed the often-touted claim that ‘olfactory abstraction is impossible’ [19] by providing mostly concrete language in response to odours, Jahai speakers overwhelmingly described odours with dedicated, abstract language. In addition, their responses were faster and shorter, providing converging evidence that the Jahai are communicatively adept in talking about odours.Even for the monomolecular odours used in this study, which do not have a single object entity associated with them, Dutch participants predominantly tried to identify a source (e.g. flowers), or situation (e.g. house that isn't aired), corresponding to that aroma.","29915007~Conclusion~1"
"29915007","Conclusion",2,"Their grappling to identify concrete sources was in sharp contrast to the fluent abstract Jahai responses. Previous studies have shown that Standard Average Europeans struggle to identify odours [5,13–16], as also illustrated by the Dutch here. The greater ease of linguistic expression demonstrated by the Jahai is not unique, however.","29915007~Conclusion~2"
"29915007","Conclusion",3,"It appears that hunter-gatherer communities in particular find odours easier to talk about [23]. Despite these differences in language, both groups appeared to have similar initial affective responses to odours—as measured by facial expressions—consistent with previous proposals of universally pleasant odours [24–26]. This is not an obvious result, as others have suggested that abstract concepts are more detached from sensory experience [27,28], or conversely that they are particularly valenced [29,30].","29915007~Conclusion~3"
"29915007","Conclusion",4,"As such, we could have expected the groups to diverge in their emotional expressions, so that their facial expressions were in line with their verbal content. We did not find compelling evidence of this. Note, however, that the groups could have diverged later in their facial expressions when they had fully lexicalized their conceptual content.","29915007~Conclusion~4"
"29915007","Conclusion",5,"We did not directly asses this. Instead, we focused on initial facial expressions that began within the first 2 s of participants sniffing an odour, and found strong similarities in this time window.Facial expressions are, of course, dynamic. In our data, after first appraisal, facial expressions often reflected ‘thinking’ expressions, perhaps associated with trying to retrieve words.","29915007~Conclusion~5"
"29915007","Conclusion",6,"Thereafter, participants often showed signs of ‘positive’ emotion: they frequently laughed—particularly after perceiving unpleasant smells. This laughter arguably reflects a response to the social situation of being asked to smell ‘disgusting’ smells. Consistent with this, the laughter was often accompanied by direct eye-gaze with the experimenter.","29915007~Conclusion~6"
"29915007","Conclusion",7,"Given the large differences in time to verbalize odours by Jahai and Dutch participants, it is unclear whether facial expressions at time of verbalization would provide reliable comparative data of emotion to the odour per se.The fact that both groups display similar emotional reactions to odours initially, but later diverged in their linguistic encoding thereafter provides fresh perspective on the controversial issue of whether olfactory perception proceeds by determining valence first [5,24] or by identifying a bounded, cohesive odour concept foremost [18]. Contrary to previous reaction time studies [42,43], we find that behaviourally relevant responses strongly support the valence-first theory: within the first 2 s the face already communicates whether an odour is positive or negative, but verbal identification does not happen until around 2.7 s for the Jahai, and takes almost 17 s for Dutch speakers.To conclude, odours may initially be treated in similar ways according to their pleasantness across diverse communities. But the fact that they vary in their linguistic expression across cultures suggests that the notion of what is ‘abstract’ or ‘concrete’ is in part a culturally-contingent fact.","29915007~Conclusion~7"
"33757701","V3X",1,"Trends Cogn Sci Trends Cogn Sci Trends in Cognitive Sciences1364-66131879-307XElsevier Ltd.","33757701~V3X~1"
"33757701","Keywords",1,"337577019761396S1364-6613(21)00035-810.1016/j.tics.2021.02.004Letter Olfactory Language: Context Is Everything Olofsson Jonas K.1⁎Pierzchajlo Stephen11Department of Psychology, Stockholm University, Stockholm, Sweden⁎Correspondence:2032021620212032021256419420© 2021 Elsevier Ltd. All rights reserved.2021Elsevier Ltd Since January 2020 Elsevier has created a COVID-19 resource centre with free information in English and Mandarin on the novel coronavirus COVID-19. The COVID-19 resource centre is hosted on Elsevier Connect, the company's public news and information website.","33757701~Keywords~1"
"33757701","Keywords",2,"Elsevier hereby grants permission to make all its COVID-19-related research that is available on the COVID-19 resource centre - including this research content - immediately available in Pub Med Central and other publicly funded repositories, such as the WHO COVID database with rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.Keywordslanguageolfactionlearningsensationolfactory perceptionmemory","33757701~Keywords~2"
"37027897","abstract_",1,"Human olfaction can be extraordinarily sensitive, and its most common assessment method is odor identification (OID), where everyday odors are matched to word labels in a multiple-choice format. However, many older persons are unable to identify familiar odors, a deficit that is associated with the risk of future dementia and mortality. The underlying processes subserving OID in older adults are poorly understood. Here, we analyzed error patterns in OID to test whether errors could be explained by perceptual and/or semantic similarities among the response alternatives. We investigated the OID response patterns in a large, population-based sample of older adults in Sweden (n = 2479; age 60-100 years). Olfaction was assessed by a 'Sniffin ́ TOM OID test with 16 odors; each trial involved matching a target odor to a correct label among three distractors. We analyzed the pattern of misidentifications, and the results showed that some distractors were more frequently selected than others, suggesting cognitive or perceptual factors may be present. Relatedly, we conducted a large online survey of older adults (n = 959, age 60-90 years) who were asked to imagine and rate the perceptual similarity of the target odors and the three corresponding distractors (e.g. ""How similar are these smells: apple and mint?""). We then used data from the Swedish web corpus and the Word2Vec neural network algorithm to quantify the semantic association strength between the labels of each target odor and its three distractors. These data sources were used to predict odor identification errors. We found that the error patterns were partly explained by both the semantic similarity between target-distractor pairs, and the imagined perceptual similarity of the target-distractor pair. Both factors had, however, a diminished prediction in older ages, as responses became gradually less systematic. In sum, our results suggest that OID tests not only reflect olfactory perception, but also likely involve the mental processing of odor-semantic associations. This may be the reason why these tests are useful in predicting dementia onset. Our insights into olfactory-language interactions could be harnessed to develop new olfactory tests that are tailored for specific clinical purposes.","37027897~abstract_~1"
"33400623","abstract_",1,"A longstanding debate within philosophy and neuroscience involves the extent to which sensory information is a necessary condition for conceptual knowledge. Much of our understanding of this relationship has been informed by examining the impact of congenital blindness and deafness on language and cognitive development. Relatively little is known about the ""lesser"" senses of smell and taste. Here we report a neuropsychological case-control study contrasting a young adult male (P01) diagnosed with anosmia (i.e. no olfaction) during early childhood relative to an age- and sex-matched control group. A structural MRI of P01's brain revealed profoundly atrophic/aplastic olfactory bulbs, and standardized smell testing confirmed his prior pediatric diagnosis of anosmia. Participants completed three language experiments examining comprehension, production, and subjective experiential ratings of odor salient words (e.g. sewer) and scenarios (e.g. fish market). P01's ratings of odor salience of single words were lower than all control participants, whereas his ratings on five other perceptual and affective dimensions were similar to controls. P01 produced unusual associations when cued to generate words that smelled similar to odor-neutral target words (e.g. ink → plant). In narrative picture description for odor salient scenes (e.g. bakery), P01 was indistinguishable from controls. These results suggest that odor deprivation does not overtly impair functional language use. However, subtle lexical-semantic effects of anosmia may be revealed using sensitive linguistic measures.","33400623~abstract_~1"
"33349546","abstract_",1,"The human sense of smell can accomplish astonishing feats, yet there remains a prevailing belief that olfactory language is deficient. Numerous studies with English speakers support this view: there are few terms for odors, odor talk is infrequent, and naming odors is difficult. However, this is not true across the world. Many languages have sizeable smell lexicons - smell is even grammaticalized. In addition, for some cultures smell talk is more frequent and odor naming easier. This linguistic variation is as yet unexplained but could be the result of ecological, cultural, or genetic factors or a combination thereof. Different ways of talking about smells may shape aspects of olfactory cognition too. Critically, this variation sheds new light on this important sensory modality.","33349546~abstract_~1"
"33035477","abstract_",1,"Olfactory receptor (OR) genes in humans form a special class characterized by unusually high DNA sequence diversity, which should give rise to differences in perception and behavior. In the largest genome-wide association study to date based on olfactory testing, we investigated odor perception and naming with smell tasks performed by 9,122 Icelanders, with replication in a separate sample of 2,204 individuals. We discovered an association between a low-frequency missense variant in TAAR5 and reduced intensity rating of fish odor containing trimethylamine (p.Ser95Pro, pcombined = 5.6 × 10-15). We demonstrate that TAAR5 genotype affects aversion to fish odor, reflected by linguistic descriptions of the odor and pleasantness ratings. We also discovered common sequence variants in two canonical olfactory receptor loci that associate with increased intensity and naming of licorice odor (trans-anethole: lead variant p.Lys233Asn in OR6C70, pcombined = 8.8 × 10-16 and pcombined = 1.4 × 10-9) and enhanced naming of cinnamon (trans-cinnamaldehyde; intergenic variant rs317787-T, pcombined = 5.0 × 10-17). Together, our results show that TAAR5 genotype variation influences human odor responses and highlight that sequence diversity in canonical OR genes can lead to enhanced olfactory ability, in contrast to the view that greater tolerance for mutations in the human OR repertoire leads to diminished function.","33035477~abstract_~1"
"29915007","abstract_",1,"Olfaction presents a particularly interesting arena to explore abstraction in language. Like other abstract domains, such as time, odours can be difficult to conceptualize. An odour cannot be seen or held, it can be difficult to locate in space, and for most people odours are difficult to verbalize. On the other hand, odours give rise to primary sensory experiences. Every time we inhale we are using olfaction to make sense of our environment. We present new experimental data from 30 Jahai hunter-gatherers from the Malay Peninsula and 30 matched Dutch participants from the Netherlands in an odour naming experiment. Participants smelled monomolecular odorants and named odours while reaction times, odour descriptors and facial expressions were measured. We show that while Dutch speakers relied on concrete descriptors, i.e. they referred to odour sources (e.g. smells like lemon), the Jahai used abstract vocabulary to name the same odours (e.g. musty). Despite this differential linguistic categorization, analysis of facial expressions showed that the two groups, nevertheless, had the same initial emotional reactions to odours. Critically, these cross-cultural data present a challenge for how to think about abstraction in language.This article is part of the theme issue 'Varieties of abstract concepts: development, use and representation in the brain'.","29915007~abstract_~1"
"29763790","abstract_",1,"The olfactory sense is a particularly challenging domain for cognitive science investigations of perception, memory, and language. Although many studies show that odors often are difficult to describe verbally, little is known about the associations between olfactory percepts and the words that describe them. Quantitative models of how odor experiences are described in natural language are therefore needed to understand how odors are perceived and communicated. In this study, we develop a computational method to characterize the olfaction-related semantic content of words in a large text corpus of internet sites in English. We introduce two new metrics: olfactory association index (OAI, how strongly a word is associated with olfaction) and olfactory specificity index (OSI, how specific a word is in its description of odors). We validate the OAI and OSI metrics using psychophysical datasets by showing that terms with high OAI have high ratings of perceived olfactory association and are used to describe highly familiar odors. In contrast, terms with high OSI have high inter-individual consistency in how they are applied to odors. Finally, we analyze Dravnieks's (1985) dataset of odor ratings in terms of OAI and OSI. This analysis reveals that terms that are used broadly (applied often but with moderate ratings) tend to be olfaction-unrelated and abstract (e.g., ""heavy"" or ""light""; low OAI and low OSI) while descriptors that are used selectively (applied seldom but with high ratings) tend to be olfaction-related (e.g., ""vanilla"" or ""licorice""; high OAI). Thus, OAI and OSI provide behaviorally meaningful information about olfactory language. These statistical tools are useful for future studies of olfactory perception and cognition, and might help integrate research on odor perception, neuroimaging, and corpus-based linguistic models of semantic organization.","29763790~abstract_~1"
"28816480","abstract_",1,"Olfaction is often considered a vestigial sense in humans, demoted throughout evolution to make way for the dominant sense of vision. This perspective on olfaction is reflected in how we think and talk about smells in the West, with odor imagery and odor language reported to be difficult. In the present study we demonstrate odor cognition is superior in odor-color synaesthesia, where there are additional sensory connections to odor concepts. Synaesthesia is a neurological phenomenon in which input in 1 modality leads to involuntary perceptual associations. Semantic accounts of synaesthesia posit synaesthetic associations are mediated by activation of inducing concepts. Therefore, synaesthetic associations may strengthen conceptual representations. To test this idea, we ran 6 odor-color synaesthetes and 17 matched controls on a battery of tasks exploring odor and color cognition. We found synaesthetes outperformed controls on tests of both odor and color discrimination, demonstrating for the first time enhanced perception in both the inducer (odor) and concurrent (color) modality. So, not only do synaesthetes have additional perceptual experiences in comparison to controls, their primary perceptual experience is also different. Finally, synaesthetes were more consistent and accurate at naming odors. We propose synaesthetic associations to odors strengthen odor concepts, making them more differentiated (facilitating odor discrimination) and easier to link with lexical representations (facilitating odor naming). In summary, we show for the first time that both odor language and perception is enhanced in people with synaesthetic associations to odors. (PsycINFO Database Record","28816480~abstract_~1"
"25979848","abstract_",1,"Most people find it profoundly difficult to name familiar smells. This difficulty persists even when perceptual odor processing and visual object naming are unimpaired, implying deficient sensory-specific interactions with the language system. Here we synthesize recent behavioral and neuroimaging data to develop a biologically informed framework for olfactory lexical processing in the human brain. Our central premise is that the difficulty in naming common objects through olfactory (compared with visual) stimulation is the end result of cumulative effects occurring at three successive stages of the olfactory language pathway: object perception, lexical-semantic integration, and verbalization. Understanding the neurocognitive mechanisms by which the language network interacts with olfaction can yield unique insights into the elusive nature of olfactory naming.","25979848~abstract_~1"
"23471695","abstract_",1,"It is notoriously difficult to name odours. Without the benefit of non-olfactory information, even common household smells elude our ability to name them. The neuroscientific basis for this olfactory language 'deficit' is poorly understood, and even basic models to explain how odour inputs gain access to transmodal representations required for naming have not been put forward. This study used patients with primary progressive aphasia, a clinical dementia syndrome characterized by primary deficits in language, to investigate the interactions between olfactory inputs and lexical access by assessing behavioural performance of olfactory knowledge and its relationship to brain atrophy. We specifically hypothesized that the temporal pole would play a key role in linking odour object representations to transmodal networks, given its anatomical proximity to olfactory and visual object processing areas. Behaviourally, patients with primary progressive aphasia with non-semantic subtypes were severely impaired on an odour naming task, in comparison with an age-matched control group. However, with the availability of picture cues or word cues, odour matching performance approached control levels, demonstrating an inability to retrieve but not to recognize the name and nature of the odorant. The magnitude of cortical thinning in the temporal pole was found to correlate with reductions in odour familiarity and odour matching to visual cues, whereas the inferior frontal gyrus correlated with both odour naming and matching. Volumetric changes in the mediodorsal thalamus correlated with the proportion of categorical mismatch errors, indicating a possible role of this region in error-signal monitoring to optimize recognition of associations linked to the odour. A complementary analysis of patients with the semantic subtype of primary progressive aphasia, which is associated with marked temporopolar atrophy, revealed much more pronounced impairments of odour naming and matching. In identifying the critical role of the temporal pole and inferior frontal gyrus in transmodal linking and verbalization of olfactory objects, our findings provide a new neurobiological foundation for understanding why even common odours are hard to name.","23471695~abstract_~1"
